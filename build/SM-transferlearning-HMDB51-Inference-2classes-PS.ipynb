{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning and action inference on input video segments\n",
    "In this notebook, we will demonstrate activity detection on a video segment with machine learning. We will use the MXNet framework in script mode with the gluoncv toolkit.\n",
    "\n",
    "1) We will fine-tune the pre-trained model with this custom dataset to learn the typical video patterns belonging to these 101 action classes.\n",
    "\n",
    "2) We will then deploy this model and host it on a sagemaker endpoint. \n",
    "\n",
    "3) Finally, we will  make a inference request for a test video. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and import the required gluoncv library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gluoncv in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (0.8.0)\n",
      "Requirement already satisfied: portalocker in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from gluoncv) (2.0.0)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from gluoncv) (1.4.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from gluoncv) (1.18.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from gluoncv) (2.22.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from gluoncv) (4.42.1)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from gluoncv) (3.1.3)\n",
      "Requirement already satisfied: Pillow in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from gluoncv) (7.0.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests->gluoncv) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests->gluoncv) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests->gluoncv) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests->gluoncv) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from matplotlib->gluoncv) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from matplotlib->gluoncv) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from matplotlib->gluoncv) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from matplotlib->gluoncv) (2.4.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib->gluoncv) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib->gluoncv) (45.2.0.post20200210)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/mxnet_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gluoncv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, re, os\n",
    "import numpy as np\n",
    "import uuid\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, nd, image\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "from mxnet import gluon\n",
    "\n",
    "from gluoncv.data.transforms import video\n",
    "from gluoncv import utils\n",
    "from gluoncv.model_zoo import get_model\n",
    "from gluoncv import utils\n",
    "from gluoncv.utils import export_block\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.mxnet import MXNet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the mxnet framework version = 1.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Load the UCF101 dataset as described in the gluoncv guide here https://gluon-cv.mxnet.io/build/examples_datasets/ucf101.html#sphx-glr-build-examples-datasets-ucf101-py\n",
    "\n",
    "Note : We are downloading only a tiny fraction of the entire UCF101 dataset here. You can modify the script flag below to download the entire dataset. The entire dataset size is 6.5 GB and will require update to the default volume size attached to the notebook instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training files.\n",
      "parse frames under folder datasets/youtube/rawframes\n",
      "0 videos parsed\n",
      "200 videos parsed\n",
      "400 videos parsed\n",
      "600 videos parsed\n",
      "frame folder analysis done\n",
      "1\n",
      "[([('fall/357158', 0), ('fall/357172', 0), ('fall/357179', 0), ('fall/357206', 0), ('fall/357232', 0), ('fall/357239', 0), ('fall/357243', 0), ('fall/357245', 0), ('fall/357271', 0), ('fall/357273', 0), ('fall/357278', 0), ('fall/357280', 0), ('fall/357287', 0), ('fall/357288', 0), ('fall/357290', 0), ('fall/357291', 0), ('fall/357295', 0), ('fall/357302', 0), ('fall/357310', 0), ('fall/357985', 0), ('fall/358024', 0), ('fall/358480', 0), ('fall/358498', 0), ('fall/358790', 0), ('fall/358794', 0), ('fall/358807', 0), ('fall/358908', 0), ('fall/359081', 0), ('fall/359204', 0), ('fall/359253', 0), ('fall/359260', 0), ('fall/359263', 0), ('fall/359268', 0), ('fall/359327', 0), ('fall/359334', 0), ('fall/359401', 0), ('fall/359402', 0), ('fall/359412', 0), ('fall/359414', 0), ('fall/359416', 0), ('fall/359418', 0), ('fall/359421', 0), ('fall/359424', 0), ('fall/359435', 0), ('fall/360138', 0), ('fall/365304', 0), ('fall/373831', 0), ('fall/373898', 0), ('fall/376809', 0), ('fall/376811', 0), ('fall/376828', 0), ('fall/376830', 0), ('fall/376832', 0), ('fall/376833', 0), ('fall/376835', 0), ('fall/376840', 0), ('fall/376842', 0), ('fall/376851', 0), ('fall/376873', 0), ('fall/376876', 0), ('fall/376878', 0), ('fall/376881', 0), ('fall/376882', 0), ('fall/376885', 0), ('fall/376887', 0), ('fall/376890', 0), ('fall/376892', 0), ('fall/376905', 0), ('fall/376917', 0), ('fall/376919', 0), ('fall/376926', 0), ('fall/376929', 0), ('fall/376932', 0), ('fall/376943', 0), ('fall/376947', 0), ('fall/376972', 0), ('fall/376974', 0), ('fall/376975', 0), ('fall/376977', 0), ('fall/376984', 0), ('fall/376996', 0), ('fall/376998', 0), ('fall/377000', 0), ('fall/377005', 0), ('fall/377012', 0), ('fall/377015', 0), ('fall/377022', 0), ('fall/377025', 0), ('fall/377027', 0), ('fall/377033', 0), ('fall/377036', 0), ('fall/377047', 0), ('fall/377056', 0), ('fall/377063', 0), ('fall/377065', 0), ('fall/377069', 0), ('fall/377071', 0), ('fall/377075', 0), ('fall/377081', 0), ('fall/377083', 0), ('fall/377088', 0), ('fall/377090', 0), ('fall/377093', 0), ('fall/377100', 0), ('fall/377142', 0), ('fall/377144', 0), ('fall/377149', 0), ('fall/377156', 0), ('fall/377174', 0), ('nofall/358844', 1), ('nofall/360952', 1), ('nofall/360986', 1), ('nofall/362937', 1), ('nofall/366191', 1), ('nofall/367081', 1), ('nofall/373196', 1), ('nofall/374375', 1), ('nofall/374538', 1), ('nofall/374543', 1), ('nofall/374590', 1), ('nofall/374608', 1), ('nofall/374616', 1), ('nofall/374629', 1), ('nofall/374983', 1), ('nofall/375017', 1), ('nofall/375026', 1), ('nofall/375118', 1), ('nofall/375123', 1), ('nofall/375165', 1), ('nofall/375205', 1), ('nofall/375522', 1), ('nofall/375580', 1), ('nofall/375592', 1), ('nofall/375594', 1), ('nofall/375609', 1), ('nofall/375614', 1), ('nofall/375620', 1), ('nofall/375635', 1), ('nofall/375650', 1), ('nofall/375663', 1), ('nofall/375669', 1), ('nofall/375671', 1), ('nofall/375681', 1), ('nofall/375689', 1), ('nofall/375691', 1), ('nofall/375695', 1), ('nofall/375701', 1), ('nofall/375707', 1), ('nofall/375721', 1), ('nofall/375728', 1), ('nofall/375730', 1), ('nofall/375736', 1), ('nofall/375746', 1), ('nofall/375748', 1), ('nofall/375763', 1), ('nofall/375843', 1), ('nofall/375845', 1), ('nofall/375847', 1), ('nofall/375849', 1), ('nofall/375853', 1), ('nofall/375855', 1), ('nofall/375857', 1), ('nofall/375859', 1), ('nofall/375861', 1), ('nofall/375863', 1), ('nofall/375865', 1), ('nofall/375867', 1), ('nofall/375869', 1), ('nofall/375871', 1), ('nofall/375873', 1), ('nofall/375879', 1), ('nofall/375890', 1), ('nofall/375893', 1), ('nofall/375895', 1), ('nofall/375897', 1), ('nofall/375899', 1), ('nofall/375902', 1), ('nofall/375904', 1), ('nofall/375908', 1), ('nofall/375910', 1), ('nofall/375912', 1), ('nofall/375916', 1), ('nofall/375919', 1), ('nofall/375921', 1), ('nofall/375923', 1), ('nofall/375927', 1), ('nofall/375932', 1), ('nofall/375946', 1), ('nofall/375950', 1), ('nofall/375954', 1), ('nofall/375958', 1), ('nofall/375959', 1), ('nofall/375962', 1), ('nofall/375968', 1), ('nofall/375976', 1), ('nofall/375978', 1), ('nofall/375979', 1), ('nofall/375980', 1), ('nofall/375983', 1), ('nofall/375986', 1), ('nofall/375988', 1), ('nofall/375999', 1), ('nofall/376020', 1), ('nofall/376073', 1), ('nofall/376085', 1), ('nofall/376089', 1), ('nofall/376097', 1), ('nofall/376101', 1), ('nofall/376107', 1), ('nofall/376109', 1), ('nofall/376124', 1), ('nofall/376126', 1), ('nofall/376131', 1), ('nofall/376183', 1), ('nofall/376191', 1), ('nofall/376213', 1), ('nofall/376234', 1), ('nofall/376247', 1)], [('fall/377216', 0), ('fall/377493', 0), ('fall/377558', 0), ('fall/377582', 0), ('fall/377594', 0), ('fall/377607', 0), ('fall/377609', 0), ('fall/377627', 0), ('fall/377629', 0), ('fall/377631', 0), ('fall/377633', 0), ('fall/377634', 0), ('fall/377636', 0), ('fall/377652', 0), ('fall/377671', 0), ('fall/377719', 0), ('fall/377730', 0), ('fall/377776', 0), ('fall/377778', 0), ('fall/377780', 0), ('fall/377782', 0), ('fall/377784', 0), ('fall/377786', 0), ('fall/377810', 0), ('fall/377816', 0), ('fall/378534', 0), ('fall/378536', 0), ('fall/379802', 0), ('fall/380486', 0), ('fall/380487', 0), ('fall/380492', 0), ('nofall/384475', 1), ('nofall/384477', 1), ('nofall/384492', 1), ('nofall/384543', 1), ('nofall/384547', 1), ('nofall/384563', 1), ('nofall/384567', 1), ('nofall/384596', 1), ('nofall/384601', 1), ('nofall/384658', 1), ('nofall/384705', 1), ('nofall/384715', 1), ('nofall/384720', 1), ('nofall/384726', 1), ('nofall/384728', 1), ('nofall/384772', 1), ('nofall/384791', 1), ('nofall/384806', 1), ('nofall/384827', 1), ('nofall/384833', 1), ('nofall/384835', 1), ('nofall/384843', 1), ('nofall/384845', 1), ('nofall/384871', 1), ('nofall/384875', 1), ('nofall/384897', 1), ('nofall/384906', 1), ('nofall/384910', 1), ('nofall/384941', 1), ('nofall/384985', 1), ('nofall/385000', 1)])]\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "#!pip install rarfile --user\n",
    "#!pip install Cython --user\n",
    "#!pip install mmcv --user\n",
    "#!pip install torch --user\n",
    "#!python data-prep-code/ucf101.py --tiny_dataset\n",
    "#!python data-prep-code/hmdb51.py\n",
    "!python data-prep-code/youtube.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Raw frames have been extracted from the videos in a folder for each video. \n",
    "\n",
    "2) A settings file has been generated. There are three items in each line, separated by spaces. The first item is the path to your training videos, e.g., video_001. It should be a folder containing the frames of video_001.mp4. The second item is the number of frames in each video, e.g., 200. The third item is the label of the videos, e.g., 0.\n",
    "\n",
    "Upload the raw frames and the settings list to S3 (can take upto 15 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1605866097.2462451\n",
      "1605868971.7678823\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(time.time())\n",
    "sagemaker_session.upload_data(path='datasets/youtube/rawframes/', key_prefix='data/youtube/rawframes')\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1605869451.1829128\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "sagemaker_session.upload_data(path='datasets/youtube/testTrain_splits/', key_prefix='data/youtube/testTrain_splits')\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name=sagemaker_session.default_bucket()\n",
    "inputs = 's3://' + bucket_name + '/data/youtube'\n",
    "\n",
    "output_path = 'i3d_transfer_learning_ps/output/'\n",
    "code_location = 'i3d_transfer_learning_ps/code/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning \n",
    "Transfer learning focuses on storing knowledge gained while solving one task and applying it to a different but related task. \n",
    "\n",
    "I3D (Inflated 3D Networks) is a widely adopted 3D video classification network. It uses 3D convolution to learn spatiotemporal information directly from videos. I3D is proposed to improve C3D (Convolutional 3D Networks) by inflating from 2D models. We can not only reuse the 2D models’ architecture (e.g., ResNet, Inception), but also bootstrap the model weights from 2D pretrained models. In this manner, training 3D networks for video classification is feasible and getting much better results.\n",
    "\n",
    "In this example, we use Inflated 3D model (I3D) with ResNet50 backbone trained on Kinetics400 dataset.\n",
    "\n",
    "Dataset size is a big factor in the performance of deep learning models. Kinetics400 has 306,245 short trimmed videos from 400 action categories. However, most often we dont have so much labeled data in another domain. Training a deep learning model on small datasets may lead to severe overfitting. \n",
    "\n",
    "Transfer learning is a technique that addresses this problem. The idea is simple: start training with a pre-trained model, instead of starting from scratch. For simple fine-tuning, just replace the last classification (dense) layer to the number of classes in the dataset. We can obtain good models on our own data without large annotated datasets and with less computing resource utilization for training.\n",
    "\n",
    "Review the following training script as the entrypoint script to the MXNet estimator framework. The script executes training with the following steps : \n",
    "\n",
    "1) Data transformation \n",
    "\n",
    " The transformation function does three things: center crop the image to 224x224 in size, transpose it to num_channels*num_frames*height*width, and normalize with mean and standard deviation calculated across all ImageNet images.\n",
    "\n",
    "2) Data loader\n",
    "\n",
    "Use the general gluoncv dataloader VideoClsCustom to load the data with num_frames = 32 as the length. For another dataset, you can just replace the value of root and setting to your data directory and your prepared text file.\n",
    "\n",
    "3) Model training \n",
    "\n",
    "a) Load the pre-trained model.\n",
    "\n",
    "b) Load input hyperparameters and number of action classes.\n",
    "\n",
    "c) Re-define the output layer for the new task. In GluonCV, you can get your customized model with one line of code.\n",
    "\n",
    "d) Define optimizer, loss and metric. Train the network for the new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\r\n",
      "# SPDX-License-Identifier: MIT-0\r\n",
      "\r\n",
      "from __future__ import print_function\r\n",
      "\r\n",
      "import argparse\r\n",
      "import logging\r\n",
      "import os\r\n",
      "import numpy as np\r\n",
      "import json\r\n",
      "import time\r\n",
      "\r\n",
      "import mxnet as mx\r\n",
      "from mxnet import gluon\r\n",
      "from mxnet.gluon import nn\r\n",
      "from mxnet import autograd as ag\r\n",
      "from mxnet.gluon.data.vision import transforms\r\n",
      "\r\n",
      "import gluoncv as gcv\r\n",
      "from gluoncv.data.transforms import video\r\n",
      "from gluoncv.data import VideoClsCustom\r\n",
      "from gluoncv.model_zoo import get_model\r\n",
      "from gluoncv.utils import makedirs, LRSequential, LRScheduler, split_and_load, TrainingHistory\r\n",
      "\r\n",
      "logging.basicConfig(level=logging.DEBUG)\r\n",
      "\r\n",
      "# ------------------------------------------------------------ #\r\n",
      "# Training methods                                             #\r\n",
      "# ------------------------------------------------------------ #\r\n",
      "\r\n",
      "\r\n",
      "def train(args):\r\n",
      "    # SageMaker passes num_cpus, num_gpus and other args we can use to tailor training to\r\n",
      "    # the current container environment\r\n",
      "    num_gpus = mx.context.num_gpus()\r\n",
      "    ctx = [mx.gpu(i) for i in range(num_gpus)] if num_gpus > 0 else [mx.cpu()]\r\n",
      "    # retrieve the hyperparameters we set in notebook (with some defaults)\r\n",
      "    \r\n",
      "    #number of training examples utilized in one iteration.\r\n",
      "    batch_size = args.batch_size\r\n",
      "    #number of times an entire dataset is passed forward and backward through the neural network \r\n",
      "    epochs = args.epochs\r\n",
      "    #tuning parameter in an optimization algorithm that determines the step size at each iteration while moving toward a   minimum of a loss function.\r\n",
      "    learning_rate = args.learning_rate\r\n",
      "    #Momentum remembers the update Δ w at each iteration, and determines the next update as a linear combination of the gradient and the previous update\r\n",
      "    momentum = args.momentum\r\n",
      "    #Optimizers are algorithms or methods used to change the attributes of your neural network such as weights and learning rate in order to reduce the losses. \r\n",
      "    optimizer = args.optimizer\r\n",
      "    #after each update, the weights are multiplied by a factor slightly less than 1.\r\n",
      "    wd = args.wd\r\n",
      "    optimizer_params = {'learning_rate': learning_rate, 'wd': wd, 'momentum': momentum}\r\n",
      "    log_interval = args.log_interval\r\n",
      "    \r\n",
      "    #In this example, we use Inflated 3D model (I3D) with ResNet50 backbone trained on Kinetics400 dataset. We want to replace the last classification (dense) layer to the number of classes in the dataset. \r\n",
      "    model_name = 'i3d_resnet50_v1_hmdb51'\r\n",
      "    #number of classes in the dataset\r\n",
      "    nclass = 2\r\n",
      "    #number of workers for the data loader\r\n",
      "    num_workers = 1\r\n",
      "    \r\n",
      "    current_host = args.current_host\r\n",
      "    hosts = args.hosts\r\n",
      "    model_dir = args.model_dir\r\n",
      "    CHECKPOINTS_DIR = '/opt/ml/checkpoints'\r\n",
      "    checkpoints_enabled = os.path.exists(CHECKPOINTS_DIR)\r\n",
      "\r\n",
      "    data_dir = args.train\r\n",
      "    segments = 'rawframes'\r\n",
      "    train ='testTrain_splits/youtube_train_list_rawframes.txt'\r\n",
      "    \r\n",
      "    #load the data with data loader\r\n",
      "    train_data = load_data(data_dir,batch_size,num_workers,segments,train)\r\n",
      "    # define the network\r\n",
      "    net = define_network(ctx,model_name,nclass)\r\n",
      "    #define the gluon trainer\r\n",
      "    trainer = gluon.Trainer(net.collect_params(), optimizer, optimizer_params)\r\n",
      "    #define loss function\r\n",
      "    loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()\r\n",
      "    #define training metric\r\n",
      "    train_metric = mx.metric.Accuracy()\r\n",
      "    train_history = TrainingHistory(['training-acc'])\r\n",
      "    net.hybridize()\r\n",
      "    #learning rate decay hyperparameters\r\n",
      "    lr_decay_count = 0\r\n",
      "    lr_decay = 0.1\r\n",
      "    lr_decay_epoch = [40, 80, 100]\r\n",
      "    for epoch in range(epochs):\r\n",
      "        tic = time.time()\r\n",
      "        train_metric.reset()\r\n",
      "        train_loss = 0\r\n",
      "\r\n",
      "        # Learning rate decay\r\n",
      "        if epoch == lr_decay_epoch[lr_decay_count]:\r\n",
      "            trainer.set_learning_rate(trainer.learning_rate*lr_decay)\r\n",
      "            lr_decay_count += 1\r\n",
      "\r\n",
      "        # Loop through each batch of training data\r\n",
      "        for i, batch in enumerate(train_data):\r\n",
      "            # Extract data and label\r\n",
      "            data = split_and_load(batch[0], ctx_list=ctx, batch_axis=0,even_split=False)\r\n",
      "            label = split_and_load(batch[1], ctx_list=ctx, batch_axis=0,even_split=False)\r\n",
      "\r\n",
      "            # AutoGrad\r\n",
      "            with ag.record():\r\n",
      "                output = []\r\n",
      "                for _, X in enumerate(data):\r\n",
      "                    X = X.reshape((-1,) + X.shape[2:])\r\n",
      "                    pred = net(X)\r\n",
      "                    output.append(pred)\r\n",
      "                loss = [loss_fn(yhat, y) for yhat, y in zip(output, label)]\r\n",
      "\r\n",
      "            # Backpropagation\r\n",
      "            for l in loss:\r\n",
      "                l.backward()\r\n",
      "\r\n",
      "            # Optimize\r\n",
      "            trainer.step(batch_size)\r\n",
      "\r\n",
      "            # Update metrics\r\n",
      "            train_loss += sum([l.mean().asscalar() for l in loss])\r\n",
      "            train_metric.update(label, output)\r\n",
      "\r\n",
      "            if i == 100:\r\n",
      "                break\r\n",
      "\r\n",
      "        name, acc = train_metric.get()\r\n",
      "\r\n",
      "        # Update history and print metrics\r\n",
      "        train_history.update([acc])\r\n",
      "        print('[Epoch %d] train=%f loss=%f time: %f' %\r\n",
      "            (epoch, acc, train_loss / (i+1), time.time()-tic))\r\n",
      "\r\n",
      "    print('saving the model')\r\n",
      "    save(net, model_dir)\r\n",
      "     \r\n",
      "def save(net, model_dir):\r\n",
      "    # save the model\r\n",
      "    net.export('%s/model'% model_dir)\r\n",
      "\r\n",
      "\r\n",
      "def define_network(ctx,model_name,nclass):\r\n",
      "    #In GluonCV, we can get a customized model with one line of code.\r\n",
      "    net = get_model(name=model_name, nclass=nclass)\r\n",
      "    net.collect_params().reset_ctx(ctx)\r\n",
      "    print(net)\r\n",
      "    return net\r\n",
      "\r\n",
      "\r\n",
      "def load_data(data_dir, batch_size,num_workers,segments,train):\r\n",
      "\r\n",
      "    #The transformation function does three things: center crop the image to 224x224 in size, transpose it to num_channels,num_frames,height*width, and normalize with mean and standard deviation calculated across all ImageNet images.\r\n",
      "\r\n",
      "    #Use the general gluoncv dataloader VideoClsCustom to load the data with num_frames = 32 as the length. For another  dataset, you can just replace the value of root and setting to your data directory and your prepared text file.\r\n",
      "    \r\n",
      "    transform_train = video.VideoGroupTrainTransform(size=(224, 224), scale_ratios=[1.0, 0.8], mean=[0.485, 0.456, 0.406], \r\n",
      "                                                          std=[0.229, 0.224, 0.225])\r\n",
      "    train_dataset = VideoClsCustom(root=data_dir + '/' + \r\n",
      "                                   segments,setting=data_dir + '/' + train,train=True,new_length=32,transform=transform_train)\r\n",
      "    print(os.listdir(data_dir+ '/' + segments))\r\n",
      "    print('Load %d training samples.' % len(train_dataset))\r\n",
      "    return gluon.data.DataLoader(train_dataset, batch_size=batch_size,\r\n",
      "                                                   shuffle=True, num_workers=num_workers)\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "# ------------------------------------------------------------ #\r\n",
      "# Training execution                                           #\r\n",
      "# ------------------------------------------------------------ #\r\n",
      "\r\n",
      "def parse_args():\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "\r\n",
      "    parser.add_argument('--batch-size', type=int, default=8)\r\n",
      "    parser.add_argument('--epochs', type=int, default=10)\r\n",
      "    parser.add_argument('--learning-rate', type=float, default=0.001)\r\n",
      "    parser.add_argument('--momentum', type=float, default=0.9)\r\n",
      "    parser.add_argument('--wd', type=float, default=0.0001)\r\n",
      "    parser.add_argument('--log-interval', type=float, default=100)\r\n",
      "\r\n",
      "    parser.add_argument('--optimizer', type=str, default='sgd')\r\n",
      "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\r\n",
      "    parser.add_argument('--train', type=str, default=os.environ['SM_CHANNEL_TRAINING'])\r\n",
      "\r\n",
      "    parser.add_argument('--current-host', type=str, default=os.environ['SM_CURRENT_HOST'])\r\n",
      "    parser.add_argument('--hosts', type=list, default=json.loads(os.environ['SM_HOSTS']))\r\n",
      "\r\n",
      "    return parser.parse_args()\r\n",
      "\r\n",
      "\r\n",
      "if __name__ == '__main__':\r\n",
      "    args = parse_args()\r\n",
      "\r\n",
      "    train(args)"
     ]
    }
   ],
   "source": [
    "!cat transfer-learning-code-2classes/transfer_learning-ps.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the MXNet estimator to prepare for training. We use a p3 instance 'ml.p3.2xlarge' here to demonstrate gpu based training. You can update the instance type based on your dataset size and expected training times.\n",
    "\n",
    "Training time recorded for the current dataset with 'ml.p3.2xlarge' is approximately 5 minutes.\n",
    "\n",
    "Instance types for SageMaker are available here https://aws.amazon.com/sagemaker/pricing/instance-types/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MXNet(\"transfer_learning-ps.py\",\n",
    "          source_dir=\"transfer-learning-code-2classes/\",\n",
    "          debugger_hook_config=False,\n",
    "          role=role,\n",
    "          output_path='s3://' + bucket_name + '/' + output_path,\n",
    "          code_location='s3://' + bucket_name + '/' + code_location,\n",
    "          train_instance_count=1,\n",
    "          train_instance_type=\"ml.p3.2xlarge\",\n",
    "          framework_version=\"1.6.0\",\n",
    "          py_version=\"py3\",\n",
    "          hyperparameters={'batch-size': 8,\n",
    "                           'epochs': 30,\n",
    "                           'learning-rate': 0.001,\n",
    "                           'wd': 0.0001,\n",
    "                           'momentum': 0.9, \n",
    "                           'log-interval': 100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch a training job "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eedfcc1f-b971-485c-bc84-ab5c482c2220\n",
      "2020-11-20 12:12:09 Starting - Starting the training job...\n",
      "2020-11-20 12:12:11 Starting - Launching requested ML instances......\n",
      "2020-11-20 12:13:15 Starting - Preparing the instances for training......\n",
      "2020-11-20 12:14:17 Downloading - Downloading input data....................................\n",
      "2020-11-20 12:20:35 Training - Downloading the training image...\n",
      "2020-11-20 12:20:55 Training - Training image download completed. Training in progress.\u001b[34m2020-11-20 12:20:56,339 sagemaker-training-toolkit INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
      "\u001b[34m2020-11-20 12:20:56,364 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_HOSTS': '[\"algo-1\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"batch-size\":8,\"epochs\":30,\"learning-rate\":0.001,\"log-interval\":100,\"momentum\":0.9,\"wd\":0.0001}', 'SM_USER_ENTRY_POINT': 'transfer_learning-ps.py', 'SM_FRAMEWORK_PARAMS': '{}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}', 'SM_INPUT_DATA_CONFIG': '{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"training\"]', 'SM_CURRENT_HOST': 'algo-1', 'SM_MODULE_NAME': 'transfer_learning-ps', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '8', 'SM_NUM_GPUS': '1', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': 's3://sagemaker-eu-west-1-646744545246/i3d_transfer_learning_ps/code//eedfcc1f-b971-485c-bc84-ab5c482c2220/source/sourcedir.tar.gz', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":8,\"epochs\":30,\"learning-rate\":0.001,\"log-interval\":100,\"momentum\":0.9,\"wd\":0.0001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"eedfcc1f-b971-485c-bc84-ab5c482c2220\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-646744545246/i3d_transfer_learning_ps/code//eedfcc1f-b971-485c-bc84-ab5c482c2220/source/sourcedir.tar.gz\",\"module_name\":\"transfer_learning-ps\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"transfer_learning-ps.py\"}', 'SM_USER_ARGS': '[\"--batch-size\",\"8\",\"--epochs\",\"30\",\"--learning-rate\",\"0.001\",\"--log-interval\",\"100\",\"--momentum\",\"0.9\",\"--wd\",\"0.0001\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_TRAINING': '/opt/ml/input/data/training', 'SM_HP_BATCH-SIZE': '8', 'SM_HP_LOG-INTERVAL': '100', 'SM_HP_LEARNING-RATE': '0.001', 'SM_HP_EPOCHS': '30', 'SM_HP_WD': '0.0001', 'SM_HP_MOMENTUM': '0.9'}\u001b[0m\n",
      "\u001b[34m2020-11-20 12:20:56,752 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3 in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (1.16.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: gluoncv in /usr/local/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (0.6.0)\u001b[0m\n",
      "\u001b[34mCollecting opencv-python\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/80/10a9ae6fa0940f25af32739d1dc6dfdbbdc79af3f04c5ea1a6de4303cd54/opencv_python-4.4.0.46-cp36-cp36m-manylinux2014_x86_64.whl (49.5MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore<1.20.0,>=1.19.10 in /usr/local/lib/python3.6/site-packages (from boto3->-r requirements.txt (line 1)) (1.19.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/site-packages (from boto3->-r requirements.txt (line 1)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/site-packages (from boto3->-r requirements.txt (line 1)) (0.3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Pillow in /usr/local/lib/python3.6/site-packages (from gluoncv->-r requirements.txt (line 2)) (8.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /usr/local/lib/python3.6/site-packages (from gluoncv->-r requirements.txt (line 2)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /usr/local/lib/python3.6/site-packages (from gluoncv->-r requirements.txt (line 2)) (1.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /usr/local/lib/python3.6/site-packages (from gluoncv->-r requirements.txt (line 2)) (4.39.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /usr/local/lib/python3.6/site-packages (from gluoncv->-r requirements.txt (line 2)) (2.22.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/site-packages (from gluoncv->-r requirements.txt (line 2)) (3.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: portalocker in /usr/local/lib/python3.6/site-packages (from gluoncv->-r requirements.txt (line 2)) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.26,>=1.25.4; python_version != \"3.4\" in /usr/local/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.10->boto3->-r requirements.txt (line 1)) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/site-packages (from botocore<1.20.0,>=1.19.10->boto3->-r requirements.txt (line 1)) (2.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests->gluoncv->-r requirements.txt (line 2)) (2.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests->gluoncv->-r requirements.txt (line 2)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests->gluoncv->-r requirements.txt (line 2)) (2020.6.20)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/site-packages (from matplotlib->gluoncv->-r requirements.txt (line 2)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/site-packages (from matplotlib->gluoncv->-r requirements.txt (line 2)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/site-packages (from matplotlib->gluoncv->-r requirements.txt (line 2)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.10->boto3->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: opencv-python\u001b[0m\n",
      "\u001b[34mSuccessfully installed opencv-python-4.4.0.46\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 19.3.1; however, version 20.2.4 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-11-20 12:21:01,243 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 8,\n",
      "        \"log-interval\": 100,\n",
      "        \"learning-rate\": 0.001,\n",
      "        \"epochs\": 30,\n",
      "        \"wd\": 0.0001,\n",
      "        \"momentum\": 0.9\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"eedfcc1f-b971-485c-bc84-ab5c482c2220\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-west-1-646744545246/i3d_transfer_learning_ps/code//eedfcc1f-b971-485c-bc84-ab5c482c2220/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"transfer_learning-ps\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"transfer_learning-ps.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":8,\"epochs\":30,\"learning-rate\":0.001,\"log-interval\":100,\"momentum\":0.9,\"wd\":0.0001}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=transfer_learning-ps.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=transfer_learning-ps\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-eu-west-1-646744545246/i3d_transfer_learning_ps/code//eedfcc1f-b971-485c-bc84-ab5c482c2220/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":8,\"epochs\":30,\"learning-rate\":0.001,\"log-interval\":100,\"momentum\":0.9,\"wd\":0.0001},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"eedfcc1f-b971-485c-bc84-ab5c482c2220\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-646744545246/i3d_transfer_learning_ps/code//eedfcc1f-b971-485c-bc84-ab5c482c2220/source/sourcedir.tar.gz\",\"module_name\":\"transfer_learning-ps\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"transfer_learning-ps.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"8\",\"--epochs\",\"30\",\"--learning-rate\",\"0.001\",\"--log-interval\",\"100\",\"--momentum\",\"0.9\",\"--wd\",\"0.0001\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=8\u001b[0m\n",
      "\u001b[34mSM_HP_LOG-INTERVAL=100\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING-RATE=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=30\u001b[0m\n",
      "\u001b[34mSM_HP_WD=0.0001\u001b[0m\n",
      "\u001b[34mSM_HP_MOMENTUM=0.9\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 transfer_learning-ps.py --batch-size 8 --epochs 30 --learning-rate 0.001 --log-interval 100 --momentum 0.9 --wd 0.0001\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m['nofall', 'fall']\u001b[0m\n",
      "\u001b[34mLoad 218 training samples.\u001b[0m\n",
      "\u001b[34mINFO:root:Model file not found. Downloading.\u001b[0m\n",
      "\u001b[34mDownloading /root/.mxnet/models/resnet50_v1b-0ecdba34.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/resnet50_v1b-0ecdba34.zip...\u001b[0m\n",
      "\u001b[34mDEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): apache-mxnet.s3-accelerate.dualstack.amazonaws.com:443\u001b[0m\n",
      "\u001b[34mDEBUG:urllib3.connectionpool:https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com:443 \"GET /gluon/models/resnet50_v1b-0ecdba34.zip HTTP/1.1\" 200 56671766\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/55344 [00:00<?, ?KB/s]#015  0%|          | 33/55344 [00:00<03:17, 280.42KB/s]#015  0%|          | 102/55344 [00:00<02:47, 329.99KB/s]#015  0%|          | 241/55344 [00:00<02:11, 418.95KB/s]#015  1%|          | 513/55344 [00:00<01:38, 554.20KB/s]#015  2%|▏         | 1073/55344 [00:00<01:12, 752.85KB/s]#015  4%|▍         | 2193/55344 [00:00<00:51, 1039.02KB/s]#015  8%|▊         | 4417/55344 [00:00<00:35, 1448.93KB/s]#015 16%|█▌        | 8793/55344 [00:00<00:22, 2034.67KB/s]#015 25%|██▍       | 13563/55344 [00:01<00:14, 2854.49KB/s]#015 32%|███▏      | 17470/55344 [00:01<00:09, 3954.04KB/s]#015 39%|███▊      | 21348/55344 [00:01<00:06, 5412.12KB/s]#015 45%|████▌     | 25084/55344 [00:01<00:04, 7279.61KB/s]#015 53%|█████▎    | 29307/55344 [00:01<00:02, 9680.82KB/s]#015 62%|██████▏   | 34139/55344 [00:01<00:01, 12645.32KB/s]#015 71%|███████   | 39091/55344 [00:01<00:00, 16282.61KB/s]#015 78%|███████▊  | 43291/55344 [00:01<00:00, 19802.23KB/s]#015 86%|████████▌ | 47430/55344 [00:01<00:00, 23051.79KB/s]#015 93%|█████████▎| 51448/55344 [00:01<00:00, 26367.32KB/s]#015100%|██████████| 55344/55344 [00:02<00:00, 26462.53KB/s]\u001b[0m\n",
      "\u001b[34mconv0_weight is done with shape:  (64, 3, 5, 7, 7)\u001b[0m\n",
      "\u001b[34mbatchnorm0_gamma is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mbatchnorm0_beta is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mbatchnorm0_running_mean is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mbatchnorm0_running_var is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_0_conv0_weight is done with shape:  (64, 64, 3, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer1_0_batchnorm0_gamma is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_0_batchnorm0_beta is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_0_batchnorm0_running_mean is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_0_batchnorm0_running_var is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_0_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\u001b[0m\n",
      "\u001b[34mlayer1_0_batchnorm1_gamma is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_0_batchnorm1_beta is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_0_batchnorm1_running_mean is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_0_batchnorm1_running_var is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_0_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer1_0_batchnorm2_gamma is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer1_0_batchnorm2_beta is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer1_0_batchnorm2_running_mean is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer1_0_batchnorm2_running_var is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer1_downsample_conv0_weight is done with shape:  (256, 64, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer1_downsample_batchnorm0_gamma is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer1_downsample_batchnorm0_beta is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer1_downsample_batchnorm0_running_mean is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer1_downsample_batchnorm0_running_var is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer1_1_conv0_weight is done with shape:  (64, 256, 3, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer1_1_batchnorm0_gamma is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_1_batchnorm0_beta is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_1_batchnorm0_running_mean is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_1_batchnorm0_running_var is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_1_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\u001b[0m\n",
      "\u001b[34mlayer1_1_batchnorm1_gamma is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_1_batchnorm1_beta is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_1_batchnorm1_running_mean is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_1_batchnorm1_running_var is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_1_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer1_1_batchnorm2_gamma is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer1_1_batchnorm2_beta is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer1_1_batchnorm2_running_mean is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer1_1_batchnorm2_running_var is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer1_2_conv0_weight is done with shape:  (64, 256, 3, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer1_2_batchnorm0_gamma is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_2_batchnorm0_beta is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_2_batchnorm0_running_mean is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_2_batchnorm0_running_var is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_2_conv1_weight is done with shape:  (64, 64, 1, 3, 3)\u001b[0m\n",
      "\u001b[34mlayer1_2_batchnorm1_gamma is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_2_batchnorm1_beta is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_2_batchnorm1_running_mean is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_2_batchnorm1_running_var is done with shape:  (64,)\u001b[0m\n",
      "\u001b[34mlayer1_2_conv2_weight is done with shape:  (256, 64, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer1_2_batchnorm2_gamma is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer1_2_batchnorm2_beta is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer1_2_batchnorm2_running_mean is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer1_2_batchnorm2_running_var is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer2_0_conv0_weight is done with shape:  (128, 256, 3, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer2_0_batchnorm0_gamma is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_0_batchnorm0_beta is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_0_batchnorm0_running_mean is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_0_batchnorm0_running_var is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_0_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\u001b[0m\n",
      "\u001b[34mlayer2_0_batchnorm1_gamma is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_0_batchnorm1_beta is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_0_batchnorm1_running_mean is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_0_batchnorm1_running_var is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_0_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer2_0_batchnorm2_gamma is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer2_0_batchnorm2_beta is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer2_0_batchnorm2_running_mean is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer2_0_batchnorm2_running_var is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer2_downsample_conv0_weight is done with shape:  (512, 256, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer2_downsample_batchnorm0_gamma is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer2_downsample_batchnorm0_beta is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer2_downsample_batchnorm0_running_mean is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer2_downsample_batchnorm0_running_var is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer2_1_conv0_weight is done with shape:  (128, 512, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer2_1_batchnorm0_gamma is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_1_batchnorm0_beta is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_1_batchnorm0_running_mean is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_1_batchnorm0_running_var is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_1_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\u001b[0m\n",
      "\u001b[34mlayer2_1_batchnorm1_gamma is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_1_batchnorm1_beta is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_1_batchnorm1_running_mean is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_1_batchnorm1_running_var is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_1_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer2_1_batchnorm2_gamma is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer2_1_batchnorm2_beta is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer2_1_batchnorm2_running_mean is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer2_1_batchnorm2_running_var is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer2_2_conv0_weight is done with shape:  (128, 512, 3, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer2_2_batchnorm0_gamma is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_2_batchnorm0_beta is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_2_batchnorm0_running_mean is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_2_batchnorm0_running_var is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_2_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\u001b[0m\n",
      "\u001b[34mlayer2_2_batchnorm1_gamma is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_2_batchnorm1_beta is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_2_batchnorm1_running_mean is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_2_batchnorm1_running_var is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_2_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer2_2_batchnorm2_gamma is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer2_2_batchnorm2_beta is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer2_2_batchnorm2_running_mean is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer2_2_batchnorm2_running_var is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer2_3_conv0_weight is done with shape:  (128, 512, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer2_3_batchnorm0_gamma is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_3_batchnorm0_beta is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_3_batchnorm0_running_mean is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_3_batchnorm0_running_var is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_3_conv1_weight is done with shape:  (128, 128, 1, 3, 3)\u001b[0m\n",
      "\u001b[34mlayer2_3_batchnorm1_gamma is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_3_batchnorm1_beta is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_3_batchnorm1_running_mean is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_3_batchnorm1_running_var is done with shape:  (128,)\u001b[0m\n",
      "\u001b[34mlayer2_3_conv2_weight is done with shape:  (512, 128, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer2_3_batchnorm2_gamma is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer2_3_batchnorm2_beta is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer2_3_batchnorm2_running_mean is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer2_3_batchnorm2_running_var is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer3_0_conv0_weight is done with shape:  (256, 512, 3, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer3_0_batchnorm0_gamma is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_0_batchnorm0_beta is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_0_batchnorm0_running_mean is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_0_batchnorm0_running_var is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_0_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\u001b[0m\n",
      "\u001b[34mlayer3_0_batchnorm1_gamma is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_0_batchnorm1_beta is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_0_batchnorm1_running_mean is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_0_batchnorm1_running_var is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_0_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer3_0_batchnorm2_gamma is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_0_batchnorm2_beta is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_0_batchnorm2_running_mean is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_0_batchnorm2_running_var is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_downsample_conv0_weight is done with shape:  (1024, 512, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer3_downsample_batchnorm0_gamma is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_downsample_batchnorm0_beta is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_downsample_batchnorm0_running_mean is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_downsample_batchnorm0_running_var is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_1_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer3_1_batchnorm0_gamma is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_1_batchnorm0_beta is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_1_batchnorm0_running_mean is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_1_batchnorm0_running_var is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_1_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\u001b[0m\n",
      "\u001b[34mlayer3_1_batchnorm1_gamma is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_1_batchnorm1_beta is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_1_batchnorm1_running_mean is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_1_batchnorm1_running_var is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_1_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer3_1_batchnorm2_gamma is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_1_batchnorm2_beta is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_1_batchnorm2_running_mean is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_1_batchnorm2_running_var is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_2_conv0_weight is done with shape:  (256, 1024, 3, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer3_2_batchnorm0_gamma is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_2_batchnorm0_beta is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_2_batchnorm0_running_mean is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_2_batchnorm0_running_var is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_2_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\u001b[0m\n",
      "\u001b[34mlayer3_2_batchnorm1_gamma is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_2_batchnorm1_beta is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_2_batchnorm1_running_mean is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_2_batchnorm1_running_var is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_2_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer3_2_batchnorm2_gamma is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_2_batchnorm2_beta is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_2_batchnorm2_running_mean is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_2_batchnorm2_running_var is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_3_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer3_3_batchnorm0_gamma is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_3_batchnorm0_beta is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_3_batchnorm0_running_mean is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_3_batchnorm0_running_var is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_3_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\u001b[0m\n",
      "\u001b[34mlayer3_3_batchnorm1_gamma is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_3_batchnorm1_beta is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_3_batchnorm1_running_mean is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_3_batchnorm1_running_var is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_3_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer3_3_batchnorm2_gamma is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_3_batchnorm2_beta is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_3_batchnorm2_running_mean is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_3_batchnorm2_running_var is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_4_conv0_weight is done with shape:  (256, 1024, 3, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer3_4_batchnorm0_gamma is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_4_batchnorm0_beta is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_4_batchnorm0_running_mean is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_4_batchnorm0_running_var is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_4_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\u001b[0m\n",
      "\u001b[34mlayer3_4_batchnorm1_gamma is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_4_batchnorm1_beta is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_4_batchnorm1_running_mean is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_4_batchnorm1_running_var is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_4_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer3_4_batchnorm2_gamma is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_4_batchnorm2_beta is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_4_batchnorm2_running_mean is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_4_batchnorm2_running_var is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_5_conv0_weight is done with shape:  (256, 1024, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer3_5_batchnorm0_gamma is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_5_batchnorm0_beta is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_5_batchnorm0_running_mean is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_5_batchnorm0_running_var is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_5_conv1_weight is done with shape:  (256, 256, 1, 3, 3)\u001b[0m\n",
      "\u001b[34mlayer3_5_batchnorm1_gamma is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_5_batchnorm1_beta is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_5_batchnorm1_running_mean is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_5_batchnorm1_running_var is done with shape:  (256,)\u001b[0m\n",
      "\u001b[34mlayer3_5_conv2_weight is done with shape:  (1024, 256, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer3_5_batchnorm2_gamma is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_5_batchnorm2_beta is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_5_batchnorm2_running_mean is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer3_5_batchnorm2_running_var is done with shape:  (1024,)\u001b[0m\n",
      "\u001b[34mlayer4_0_conv0_weight is done with shape:  (512, 1024, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer4_0_batchnorm0_gamma is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_0_batchnorm0_beta is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_0_batchnorm0_running_mean is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_0_batchnorm0_running_var is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_0_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\u001b[0m\n",
      "\u001b[34mlayer4_0_batchnorm1_gamma is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_0_batchnorm1_beta is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_0_batchnorm1_running_mean is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_0_batchnorm1_running_var is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_0_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer4_0_batchnorm2_gamma is done with shape:  (2048,)\u001b[0m\n",
      "\u001b[34mlayer4_0_batchnorm2_beta is done with shape:  (2048,)\u001b[0m\n",
      "\u001b[34mlayer4_0_batchnorm2_running_mean is done with shape:  (2048,)\u001b[0m\n",
      "\u001b[34mlayer4_0_batchnorm2_running_var is done with shape:  (2048,)\u001b[0m\n",
      "\u001b[34mlayer4_downsample_conv0_weight is done with shape:  (2048, 1024, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer4_downsample_batchnorm0_gamma is done with shape:  (2048,)\u001b[0m\n",
      "\u001b[34mlayer4_downsample_batchnorm0_beta is done with shape:  (2048,)\u001b[0m\n",
      "\u001b[34mlayer4_downsample_batchnorm0_running_mean is done with shape:  (2048,)\u001b[0m\n",
      "\u001b[34mlayer4_downsample_batchnorm0_running_var is done with shape:  (2048,)\u001b[0m\n",
      "\u001b[34mlayer4_1_conv0_weight is done with shape:  (512, 2048, 3, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer4_1_batchnorm0_gamma is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_1_batchnorm0_beta is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_1_batchnorm0_running_mean is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_1_batchnorm0_running_var is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_1_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\u001b[0m\n",
      "\u001b[34mlayer4_1_batchnorm1_gamma is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_1_batchnorm1_beta is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_1_batchnorm1_running_mean is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_1_batchnorm1_running_var is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_1_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer4_1_batchnorm2_gamma is done with shape:  (2048,)\u001b[0m\n",
      "\u001b[34mlayer4_1_batchnorm2_beta is done with shape:  (2048,)\u001b[0m\n",
      "\u001b[34mlayer4_1_batchnorm2_running_mean is done with shape:  (2048,)\u001b[0m\n",
      "\u001b[34mlayer4_1_batchnorm2_running_var is done with shape:  (2048,)\u001b[0m\n",
      "\u001b[34mlayer4_2_conv0_weight is done with shape:  (512, 2048, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer4_2_batchnorm0_gamma is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_2_batchnorm0_beta is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_2_batchnorm0_running_mean is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_2_batchnorm0_running_var is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_2_conv1_weight is done with shape:  (512, 512, 1, 3, 3)\u001b[0m\n",
      "\u001b[34mlayer4_2_batchnorm1_gamma is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_2_batchnorm1_beta is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_2_batchnorm1_running_mean is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_2_batchnorm1_running_var is done with shape:  (512,)\u001b[0m\n",
      "\u001b[34mlayer4_2_conv2_weight is done with shape:  (2048, 512, 1, 1, 1)\u001b[0m\n",
      "\u001b[34mlayer4_2_batchnorm2_gamma is done with shape:  (2048,)\u001b[0m\n",
      "\u001b[34mlayer4_2_batchnorm2_beta is done with shape:  (2048,)\u001b[0m\n",
      "\u001b[34mlayer4_2_batchnorm2_running_mean is done with shape:  (2048,)\u001b[0m\n",
      "\u001b[34mlayer4_2_batchnorm2_running_var is done with shape:  (2048,)\u001b[0m\n",
      "\u001b[34mdense0_weight is skipped with shape:  (2, 2048)\u001b[0m\n",
      "\u001b[34mdense0_bias is skipped with shape:  (2,)\u001b[0m\n",
      "\u001b[34mINFO:root:Model file not found. Downloading.\u001b[0m\n",
      "\u001b[34mDownloading /root/.mxnet/models/i3d_resnet50_v1_kinetics400-568a722e.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/i3d_resnet50_v1_kinetics400-568a722e.zip...\u001b[0m\n",
      "\u001b[34mDEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): apache-mxnet.s3-accelerate.dualstack.amazonaws.com:443\u001b[0m\n",
      "\u001b[34mDEBUG:urllib3.connectionpool:https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com:443 \"GET /gluon/models/i3d_resnet50_v1_kinetics400-568a722e.zip HTTP/1.1\" 200 213486236\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/208483 [00:00<?, ?KB/s]#015  2%|▏         | 5097/208483 [00:00<00:04, 41137.88KB/s]#015  5%|▍         | 9407/208483 [00:00<00:04, 41705.03KB/s]#015  6%|▌         | 12771/208483 [00:00<00:05, 38905.80KB/s]#015  8%|▊         | 16866/208483 [00:00<00:04, 39496.30KB/s]#015 10%|█         | 21218/208483 [00:00<00:04, 40622.12KB/s]#015 12%|█▏        | 25281/208483 [00:00<00:04, 40552.54KB/s]#015 14%|█▍        | 29206/208483 [00:00<00:04, 40149.31KB/s]#015 16%|█▌        | 33161/208483 [00:00<00:04, 39964.05KB/s]#015 18%|█▊        | 36931/208483 [00:00<00:04, 38483.77KB/s]#015 20%|█▉        | 41372/208483 [00:01<00:04, 39192.73KB/s]#015 22%|██▏       | 46227/208483 [00:01<00:03, 41110.22KB/s]#015 24%|██▍       | 50651/208483 [00:01<00:03, 42001.35KB/s]#015 26%|██▋       | 54825/208483 [00:01<00:03, 41459.59KB/s]#015 28%|██▊       | 58954/208483 [00:01<00:03, 40543.36KB/s]#015 30%|███       | 63001/208483 [00:01<00:03, 40162.83KB/s]#015 32%|███▏      | 67013/208483 [00:01<00:03, 39841.05KB/s]#015 34%|███▍      | 71151/208483 [00:01<00:03, 40289.41KB/s]#015 36%|███▋      | 75811/208483 [00:01<00:03, 41878.03KB/s]#015 38%|███▊      | 80015/208483 [00:01<00:03, 41499.96KB/s]#015 40%|████      | 84177/208483 [00:02<00:03, 40742.08KB/s]#015 42%|████▏     | 88263/208483 [00:02<00:03, 39344.25KB/s]#015 44%|████▍     | 92279/208483 [00:02<00:02, 39584.09KB/s]#015 46%|████▌     | 96371/208483 [00:02<00:02, 39802.39KB/s]#015 48%|████▊     | 101107/208483 [00:02<00:02, 41665.58KB/s]#015 51%|█████     | 105304/208483 [00:02<00:02, 41559.16KB/s]#015 53%|█████▎    | 109481/208483 [00:02<00:02, 40804.95KB/s]#015 54%|█████▍    | 113580/208483 [00:02<00:02, 40223.82KB/s]#015 56%|█████▋    | 117617/208483 [00:02<00:02, 39703.63KB/s]#015 58%|█████▊    | 121667/208483 [00:03<00:02, 38146.81KB/s]#015 61%|██████    | 126467/208483 [00:03<00:02, 40206.66KB/s]#015 63%|██████▎   | 131019/208483 [00:03<00:01, 41664.88KB/s]#015 65%|██████▍   | 135231/208483 [00:03<00:01, 40815.12KB/s]#015 67%|██████▋   | 139348/208483 [00:03<00:01, 40336.39KB/s]#015 69%|██████▉   | 143408/208483 [00:03<00:01, 39912.92KB/s]#015 71%|███████   | 147419/208483 [00:03<00:01, 39363.11KB/s]#015 73%|███████▎  | 151891/208483 [00:03<00:01, 40235.32KB/s]#015 75%|███████▌  | 156739/208483 [00:03<00:01, 41948.65KB/s]#015 77%|███████▋  | 160964/208483 [00:03<00:01, 41819.66KB/s]#015 79%|███████▉  | 165167/208483 [00:04<00:01, 40918.66KB/s]#015 81%|████████  | 169278/208483 [00:04<00:00, 40518.64KB/s]#015 83%|████████▎ | 173344/208483 [00:04<00:00, 40182.53KB/s]#015 85%|████████▌ | 177381/208483 [00:04<00:00, 40237.48KB/s]#015 87%|████████▋ | 182163/208483 [00:04<00:00, 41030.36KB/s]#015 90%|████████▉ | 186890/208483 [00:04<00:00, 42720.46KB/s]#015 92%|█████████▏| 191187/208483 [00:04<00:00, 41711.58KB/s]#015 94%|█████████▎| 195381/208483 [00:04<00:00, 40754.67KB/s]#015 96%|█████████▌| 199477/208483 [00:04<00:00, 40371.24KB/s]#015 98%|█████████▊| 203530/208483 [00:05<00:00, 40317.49KB/s]#015100%|█████████▉| 207672/208483 [00:05<00:00, 40638.79KB/s]#015100%|██████████| 208483/208483 [00:05<00:00, 40643.21KB/s]\u001b[0m\n",
      "\u001b[34mI3D_ResNetV1(\n",
      "  (first_stage): HybridSequential(\n",
      "    (0): Conv3D(3 -> 64, kernel_size=(5, 7, 7), stride=(2, 2, 2), padding=(2, 3, 3), bias=False)\n",
      "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "    (2): Activation(relu)\n",
      "    (3): MaxPool3D(size=(1, 3, 3), stride=(2, 2, 2), padding=(0, 1, 1), ceil_mode=False, global_pool=False, pool_type=max, layout=NCDHW)\n",
      "  )\n",
      "  (pool2): MaxPool3D(size=(2, 1, 1), stride=(2, 1, 1), padding=(0, 0, 0), ceil_mode=False, global_pool=False, pool_type=max, layout=NCDHW)\n",
      "  (res_layers): HybridSequential(\n",
      "    (0): HybridSequential(\n",
      "      (0): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(64 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        )\n",
      "        (conv1): Conv3D(64 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "        (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (relu): Activation(relu)\n",
      "        (downsample): HybridSequential(\n",
      "          (0): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        )\n",
      "        (conv1): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "        (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        )\n",
      "        (conv1): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
      "        (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (1): HybridSequential(\n",
      "      (0): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(256 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        )\n",
      "        (conv1): Conv3D(256 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (relu): Activation(relu)\n",
      "        (downsample): HybridSequential(\n",
      "          (0): Conv3D(256 -> 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        )\n",
      "        (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(512 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        )\n",
      "        (conv1): Conv3D(512 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        )\n",
      "        (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
      "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (2): HybridSequential(\n",
      "      (0): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(512 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        )\n",
      "        (conv1): Conv3D(512 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        (relu): Activation(relu)\n",
      "        (downsample): HybridSequential(\n",
      "          (0): Conv3D(512 -> 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        )\n",
      "        (conv1): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        )\n",
      "        (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        )\n",
      "        (conv1): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        )\n",
      "        (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        )\n",
      "        (conv1): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
      "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "    (3): HybridSequential(\n",
      "      (0): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "        )\n",
      "        (conv1): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "        (relu): Activation(relu)\n",
      "        (downsample): HybridSequential(\n",
      "          (0): Conv3D(1024 -> 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(2048 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "        )\n",
      "        (conv1): Conv3D(2048 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "        (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (bottleneck): HybridSequential(\n",
      "          (0): Conv3D(2048 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "          (2): Activation(relu)\n",
      "          (3): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "          (5): Activation(relu)\n",
      "          (6): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "        )\n",
      "        (conv1): Conv3D(2048 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
      "        (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
      "        (relu): Activation(relu)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (st_avg): GlobalAvgPool3D(size=(1, 1, 1), stride=(1, 1, 1), padding=(0, 0, 0), ceil_mode=True, global_pool=True, pool_type=avg, layout=NCDHW)\n",
      "  (head): HybridSequential(\n",
      "    (0): Dropout(p = 0.8, axes=())\n",
      "    (1): Dense(2048 -> 2, linear)\n",
      "  )\n",
      "  (fc): Dense(2048 -> 2, linear)\u001b[0m\n",
      "\u001b[34m)\u001b[0m\n",
      "\u001b[34m[12:21:31] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[34m[12:23:32] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[34m[Epoch 0] train=0.642202 loss=0.645851 time: 127.378720\u001b[0m\n",
      "\u001b[34m[Epoch 1] train=0.876147 loss=0.412173 time: 118.332625\u001b[0m\n",
      "\u001b[34m[Epoch 2] train=0.908257 loss=0.285428 time: 117.279679\u001b[0m\n",
      "\u001b[34m[Epoch 3] train=0.912844 loss=0.268898 time: 116.038772\u001b[0m\n",
      "\u001b[34m[Epoch 4] train=0.944954 loss=0.182183 time: 121.840577\u001b[0m\n",
      "\u001b[34m[Epoch 5] train=0.967890 loss=0.148327 time: 116.061000\u001b[0m\n",
      "\u001b[34m[Epoch 6] train=0.944954 loss=0.174160 time: 116.418624\u001b[0m\n",
      "\u001b[34m[Epoch 7] train=0.935780 loss=0.174014 time: 121.380453\u001b[0m\n",
      "\u001b[34m[Epoch 8] train=0.986239 loss=0.096276 time: 115.239072\u001b[0m\n",
      "\u001b[34m[Epoch 9] train=0.990826 loss=0.048751 time: 114.748139\u001b[0m\n",
      "\u001b[34m[Epoch 10] train=0.981651 loss=0.059440 time: 115.793645\u001b[0m\n",
      "\u001b[34m[Epoch 11] train=0.995413 loss=0.038759 time: 114.642827\u001b[0m\n",
      "\u001b[34m[Epoch 12] train=0.986239 loss=0.051327 time: 117.608549\u001b[0m\n",
      "\u001b[34m[Epoch 13] train=0.990826 loss=0.058641 time: 114.435883\u001b[0m\n",
      "\u001b[34m[Epoch 14] train=1.000000 loss=0.030570 time: 116.486946\u001b[0m\n",
      "\u001b[34m[Epoch 15] train=0.977064 loss=0.053415 time: 120.375847\u001b[0m\n",
      "\u001b[34m[Epoch 16] train=0.986239 loss=0.047453 time: 114.449404\u001b[0m\n",
      "\u001b[34m[Epoch 17] train=1.000000 loss=0.011973 time: 114.024807\u001b[0m\n",
      "\u001b[34m[Epoch 18] train=1.000000 loss=0.015374 time: 115.157286\u001b[0m\n",
      "\u001b[34m[Epoch 19] train=0.995413 loss=0.027290 time: 114.224086\u001b[0m\n",
      "\u001b[34m[Epoch 20] train=0.990826 loss=0.093058 time: 115.027068\u001b[0m\n",
      "\u001b[34m[Epoch 21] train=0.986239 loss=0.049126 time: 113.626889\u001b[0m\n",
      "\u001b[34m[Epoch 22] train=0.995413 loss=0.025304 time: 115.138075\u001b[0m\n",
      "\u001b[34m[Epoch 23] train=0.995413 loss=0.018599 time: 119.896533\u001b[0m\n",
      "\u001b[34m[Epoch 24] train=1.000000 loss=0.012975 time: 113.662724\u001b[0m\n",
      "\u001b[34m[Epoch 25] train=0.990826 loss=0.017595 time: 115.497532\u001b[0m\n",
      "\u001b[34m[Epoch 26] train=1.000000 loss=0.009767 time: 119.665631\u001b[0m\n",
      "\u001b[34m[Epoch 27] train=1.000000 loss=0.012378 time: 113.429415\u001b[0m\n",
      "\u001b[34m[Epoch 28] train=1.000000 loss=0.007686 time: 114.330043\u001b[0m\n",
      "\n",
      "2020-11-20 13:19:47 Uploading - Uploading generated training model\u001b[34m[Epoch 29] train=1.000000 loss=0.021841 time: 115.824549\u001b[0m\n",
      "\u001b[34msaving the model\u001b[0m\n",
      "\u001b[34m2020-11-20 13:19:44,392 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-11-20 13:20:08 Completed - Training job completed\n",
      "Training seconds: 3951\n",
      "Billable seconds: 3951\n"
     ]
    }
   ],
   "source": [
    "JOB_NAME=str(uuid.uuid4())\n",
    "print(JOB_NAME)\n",
    "m.fit(inputs,job_name=JOB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Inference\n",
    "\n",
    "First, create a MXNet SageMaker Model that can be deployed to a SageMaker Endpoint. By default, this will use the SageMaker MXNet Inference toolkit for serving MXNet models on Amazon SageMaker. \n",
    "\n",
    "1) This will use  a default framework image for MXNet version specified.\n",
    "\n",
    "2) Provide the  S3 location of the SageMaker model data .tar.gz file.\n",
    "\n",
    "3) Provide the path  to the Python inference file which should be executed as the entry point to model hosting.\n",
    "\n",
    "4) Number of model server workers set to 10 to process parallel invocation requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eedfcc1f-b971-485c-bc84-ab5c482c2220\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "JOB_NAME='eedfcc1f-b971-485c-bc84-ab5c482c2220'\n",
    "print(JOB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-activity-detection-model-2classPS-1605878581\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.mxnet.model import MXNetModel\n",
    "sagemaker_model2 = MXNetModel(model_data = 's3://' + bucket_name + '/' + output_path  + JOB_NAME + '/output/model.tar.gz', source_dir='inference-code-2classes/',\n",
    "                                  role = role,framework_version='1.6.0',py_version='py3',entry_point='2class_inference-ps.py',model_server_workers=10,name='sagemaker-activity-detection-model-2classPS-{0}'.format(str(int(time.time()))))\n",
    "print(sagemaker_model2.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\r\n",
      "# SPDX-License-Identifier: MIT-0\r\n",
      "\r\n",
      "from __future__ import absolute_import\r\n",
      "\r\n",
      "import subprocess\r\n",
      "import sys\r\n",
      "import io\r\n",
      "import os\r\n",
      "import boto3\r\n",
      "import time\r\n",
      "import json\r\n",
      "import uuid\r\n",
      "\r\n",
      "import mxnet as mx\r\n",
      "import numpy as np\r\n",
      "from mxnet import gluon,nd\r\n",
      "from sagemaker_inference import content_types, default_inference_handler, errors\r\n",
      "from io import BytesIO\r\n",
      "from datetime import datetime\r\n",
      "\r\n",
      "\r\n",
      "import gluoncv\r\n",
      "from gluoncv.data.transforms import video\r\n",
      "from gluoncv.data import VideoClsCustom\r\n",
      "from gluoncv.utils.filesystem import try_import_decord\r\n",
      "\r\n",
      "ctx = mx.gpu(0) if mx.context.num_gpus() > 0 else mx.cpu()\r\n",
      "#HMDB51 classes\r\n",
      "classes = ['fall', 'no_fall']\r\n",
      "dict_classes = dict(zip(range(len(classes)), classes))\r\n",
      "# ------------------------------------------------------------ #\r\n",
      "# Hosting methods                                              #\r\n",
      "# ------------------------------------------------------------ #\r\n",
      "\r\n",
      "def model_fn(model_dir):\r\n",
      "    print('here')\r\n",
      "    print(ctx)\r\n",
      "    symbol = mx.sym.load('%s/model-symbol.json' % model_dir)\r\n",
      "    outputs = mx.symbol.softmax(data=symbol, name='softmax_label')\r\n",
      "    inputs = mx.sym.var('data')\r\n",
      "    net = gluon.SymbolBlock(outputs, inputs)\r\n",
      "    net.load_parameters('%s/model-0000.params' % model_dir, ctx=ctx)\r\n",
      "    return net\r\n",
      "\r\n",
      "#transform function that uses json (s3 path) as input and output\r\n",
      "def transform_fn(net, data, input_content_type, output_content_type):\r\n",
      "    print('transform_fn here')\r\n",
      "    start = time.time()\r\n",
      "    data = json.loads(data)\r\n",
      "    video_data = read_video_data(data['S3_VIDEO_PATH'])\r\n",
      "    print(time.time())\r\n",
      "    video_input = video_data.as_in_context(ctx)\r\n",
      "    probs = net(video_input.astype('float32', copy=False))\r\n",
      "    print(time.time())\r\n",
      "    predicted = mx.nd.argmax(probs, axis=1).asnumpy().tolist()[0]\r\n",
      "    probability = mx.nd.max(probs, axis=1).asnumpy().tolist()[0]\r\n",
      "    \r\n",
      "    probability = '{:.4f}'.format(probability)\r\n",
      "    predicted_name = dict_classes[int(predicted)]\r\n",
      "    total_prediction = time.time()-start\r\n",
      "    total_prediction = '{:.4f}'.format(total_prediction)\r\n",
      "    print('Model prediction probability: ',probability)\r\n",
      "    print('Model prediction label: ',predicted_name)\r\n",
      "    print('Model prediction time: ', total_prediction)\r\n",
      "    \r\n",
      "    now = datetime.utcnow()\r\n",
      "    time_format = '%Y-%m-%d %H:%M:%S %Z%z'\r\n",
      "    now = now.strftime(time_format)\r\n",
      "\r\n",
      "    response = {\r\n",
      "        'S3Path': {'S': data['S3_VIDEO_PATH']},\r\n",
      "        'Predicted': {'S': predicted_name},\r\n",
      "        'Probability': {'S': probability},\r\n",
      "        'DateCreatedUTC': {'S': now}\r\n",
      "    }\r\n",
      "\r\n",
      "    return json.dumps(response), output_content_type\r\n",
      "\r\n",
      "def get_bucket_and_key(s3_path):\r\n",
      "    \"\"\"Get the bucket name and key from the given path.\r\n",
      "    Args:\r\n",
      "        s3_path(str): Input S3 path\r\n",
      "    \"\"\"\r\n",
      "    s3_path = s3_path.replace('s3://', '')\r\n",
      "    s3_path = s3_path.replace('S3://', '') #Both cases\r\n",
      "    bucket, key = s3_path.split('/', 1)\r\n",
      "    return bucket, key\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "def read_video_data(s3_video_path, num_frames=32):\r\n",
      "    \"\"\"Read and preprocess video data from the S3 bucket.\"\"\"\r\n",
      "    print('read and preprocess video data here ')\r\n",
      "    s3_client = boto3.client('s3')\r\n",
      "    #print(uuid.uuid4())\r\n",
      "    fname = s3_video_path.replace('s3://', '')\r\n",
      "    fname = fname.replace('S3://', '')\r\n",
      "    fname = fname.replace('/', '')\r\n",
      "    #download_path = '/tmp/{}-{}'.format(uuid.uuid4(), fname)\r\n",
      "    #video_list_path = '/tmp/{}-{}'.format(uuid.uuid4(), 'video_list.txt')\r\n",
      "    download_path = '/tmp/' + fname\r\n",
      "    video_list_path = '/tmp/video_list' + str(uuid.uuid4()) + '.txt' \r\n",
      "    bucket, key = get_bucket_and_key(s3_video_path)\r\n",
      "    s3_client.download_file(bucket, key, download_path)\r\n",
      "    \r\n",
      "    #update download_path filename to be unique\r\n",
      "    filename,ext = os.path.splitext(download_path)    # save the file extension\r\n",
      "    filename = filename + str(uuid.uuid4())\r\n",
      "    os.rename(download_path, filename+ext)\r\n",
      "    download_path = filename+ext\r\n",
      "    \r\n",
      "    #Dummy duration and label with each video path\r\n",
      "    video_list = '{} {} {}'.format(download_path, 10, 1)\r\n",
      "    with open(video_list_path, 'w') as fopen:\r\n",
      "        fopen.write(video_list)\r\n",
      "\r\n",
      "    #Constants\r\n",
      "    data_dir = '/tmp/'\r\n",
      "    num_segments = 1\r\n",
      "    new_length = num_frames\r\n",
      "    new_step =1\r\n",
      "    use_decord = True\r\n",
      "    video_loader = True\r\n",
      "    slowfast = False\r\n",
      "    #Preprocessing params \r\n",
      "        \r\n",
      "    #The transformation function does three things: center crop the image to 224x224 in size, transpose it to num_channels,num_frames,height*width, and normalize with mean and standard deviation calculated across all ImageNet images.\r\n",
      "\r\n",
      "    #Use the general gluoncv dataloader VideoClsCustom to load the data with num_frames = 32 as the length.\r\n",
      "    input_size = 224\r\n",
      "    mean = [0.485, 0.456, 0.406]\r\n",
      "    std=[0.229, 0.224, 0.225]\r\n",
      "\r\n",
      "    transform = video.VideoGroupValTransform(size=input_size, mean=mean, std=std)\r\n",
      "    video_utils = VideoClsCustom(root=data_dir,\r\n",
      "                                 setting=video_list_path,\r\n",
      "                                 num_segments=num_segments,\r\n",
      "                                 new_length=new_length,\r\n",
      "                                 new_step=new_step,\r\n",
      "                                 video_loader=video_loader,\r\n",
      "                                 use_decord=use_decord,\r\n",
      "                                 slowfast=slowfast)\r\n",
      "    \r\n",
      "    #Read for the video list\r\n",
      "    video_name = video_list.split()[0]\r\n",
      "\r\n",
      "    decord = try_import_decord()\r\n",
      "    decord_vr = decord.VideoReader(video_name)\r\n",
      "    duration = len(decord_vr)\r\n",
      "\r\n",
      "    skip_length = new_length * new_step\r\n",
      "    segment_indices, skip_offsets = video_utils._sample_test_indices(duration)\r\n",
      "\r\n",
      "    if video_loader:\r\n",
      "        if slowfast:\r\n",
      "            clip_input = video_utils._video_TSN_decord_slowfast_loader(video_name, decord_vr, \r\n",
      "                                                                       duration, segment_indices, skip_offsets)\r\n",
      "        else:\r\n",
      "            clip_input = video_utils._video_TSN_decord_batch_loader(video_name, decord_vr, \r\n",
      "                                                                    duration, segment_indices, skip_offsets)\r\n",
      "    else:\r\n",
      "        raise RuntimeError('We only support video-based inference.')\r\n",
      "\r\n",
      "    clip_input = transform(clip_input)\r\n",
      "\r\n",
      "    if slowfast:\r\n",
      "        sparse_sampels = len(clip_input) // (num_segments * num_crop)\r\n",
      "        clip_input = np.stack(clip_input, axis=0)\r\n",
      "        clip_input = clip_input.reshape((-1,) + (sparse_sampels, 3, input_size, input_size))\r\n",
      "        clip_input = np.transpose(clip_input, (0, 2, 1, 3, 4))\r\n",
      "    else:\r\n",
      "        clip_input = np.stack(clip_input, axis=0)\r\n",
      "        clip_input = clip_input.reshape((-1,) + (new_length, 3, input_size, input_size))\r\n",
      "        clip_input = np.transpose(clip_input, (0, 2, 1, 3, 4))\r\n",
      "\r\n",
      "    if new_length == 1:\r\n",
      "        clip_input = np.squeeze(clip_input, axis=2)    # this is for 2D input case\r\n",
      "\r\n",
      "    clip_input = nd.array(clip_input)\r\n",
      "    \r\n",
      "    #Cleanup temp files\r\n",
      "    os.remove(download_path)\r\n",
      "    os.remove(video_list_path)\r\n",
      "    #os.system('rm {}'.format(download_path))\r\n",
      "    #os.system('rm {}'.format(video_list_path))\r\n",
      "\r\n",
      "    return clip_input\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat inference-code-2classes/2class_inference-ps.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model hosting \n",
    "\n",
    "Deploy the  model on a single g4dn instance. \n",
    "\n",
    "G4 is a good platform for  ML inference on images at low cost. G4 is based on the Turing T4 GPU which is purposed built with RTX tracing cores, tensor cores. Here is a link to inference benchmarks from Nvidia\n",
    "https://developer.nvidia.com/deep-learning-performance-training-inference .\n",
    "G4 prove to have similar throughput with higher energy efficiency wrt P3 instances, which means they are a good choice for inference tasks at a low cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "#Instance type used for deployment\n",
    "MODEL_INSTANCE_TYPE = 'ml.g4dn.2xlarge'\n",
    "#Number of instances used for deployment (could be increased based on the prediction requests)\n",
    "INSTANCE_COUNT = 1\n",
    "#Model endpoint name\n",
    "ENDPOINT_NAME = '2class-endpoint-ps'\n",
    "predictor = sagemaker_model2.deploy(initial_instance_count=INSTANCE_COUNT,instance_type=MODEL_INSTANCE_TYPE,endpoint_name=ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:sagemaker:eu-west-1:646744545246:endpoint/2class-endpoint-ps'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client = boto3.client('sagemaker')\n",
    "sm_client.describe_endpoint(EndpointName=ENDPOINT_NAME)['EndpointArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video inference test\n",
    "\n",
    "Test ML inference on videos from another free video data source (Pexels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video_file = '../videos/357280.mp4'\n",
    "#video_file = '../videos/377090.mp4'\n",
    "video_file = './datasets/youtube/videos/fall/377810.avi'\n",
    "#video_file = './datasets/hmdb51/videos/fall_floor/RETURN_OF_THE_KING_fall_floor_f_nm_np1_fr_med_49.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = sagemaker_session.upload_data(path=video_file, key_prefix='data/youtube')\n",
    "S3_VIDEO_PATH = payload\n",
    "#Dict data to be passed to the endpoint\n",
    "data = {\n",
    "    'S3_VIDEO_PATH': S3_VIDEO_PATH,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke endpoint and print results from the API with details \n",
    "1. S3 input path\n",
    "2. Output class\n",
    "3. Output probability\n",
    "4. Time of detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2class-endpoint-ps\n",
      "{'S3Path': {'S': 's3://sagemaker-eu-west-1-646744545246/data/youtube/377810.avi'}, 'Predicted': {'S': 'fall'}, 'Probability': {'S': '1.0000'}, 'DateCreatedUTC': {'S': '2020-12-01 13:50:32 '}}\n"
     ]
    }
   ],
   "source": [
    "ENDPOINT_NAME='2class-endpoint-ps'\n",
    "print(ENDPOINT_NAME)\n",
    "import time\n",
    "import json\n",
    "sm_runtime2 = boto3.Session().client('sagemaker-runtime')\n",
    "a_time = float(time.time())\n",
    "response2 = sm_runtime2.invoke_endpoint(EndpointName=ENDPOINT_NAME, ContentType='application/json',Accept='application/json',Body=json.dumps(data))\n",
    "b_time = float(time.time())\n",
    "#Get and print the response\n",
    "response_body = json.loads(response2['Body'].read().decode('utf-8'))\n",
    "#print('Inference on: ', data['S3_VIDEO_PATH'], '-', response_body['Predicted']['S'], \"{:.2f}\".format(float(response_body['Probability']['S'])*100), '% -', \"{:.1f}\".format(b_time - a_time), 'secs')\n",
    "print(response_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: awswrangler in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (1.10.0)\n",
      "Requirement already satisfied: psycopg2-binary~=2.8.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from awswrangler) (2.8.6)\n",
      "Requirement already satisfied: pymysql<0.11.0,>=0.9.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from awswrangler) (0.10.1)\n",
      "Requirement already satisfied: pyarrow~=2.0.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from awswrangler) (2.0.0)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.12.49 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from awswrangler) (1.15.16)\n",
      "Requirement already satisfied: SQLAlchemy~=1.3.10 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from awswrangler) (1.3.13)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.15.49 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from awswrangler) (1.18.16)\n",
      "Requirement already satisfied: pandas<1.2.0,>=1.1.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from awswrangler) (1.1.4)\n",
      "Requirement already satisfied: numpy<1.20.0,>=1.18.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from awswrangler) (1.18.1)\n",
      "Requirement already satisfied: sqlalchemy-redshift<0.9.0,>=0.7.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from awswrangler) (0.8.1)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from boto3<2.0.0,>=1.12.49->awswrangler) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from boto3<2.0.0,>=1.12.49->awswrangler) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from botocore<2.0.0,>=1.15.49->awswrangler) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version != \"3.4\" in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from botocore<2.0.0,>=1.15.49->awswrangler) (1.25.10)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from pandas<1.2.0,>=1.1.0->awswrangler) (2019.3)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from sqlalchemy-redshift<0.9.0,>=0.7.0->awswrangler) (20.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.15.49->awswrangler) (1.14.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from packaging->sqlalchemy-redshift<0.9.0,>=0.7.0->awswrangler) (2.4.6)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/mxnet_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "###Iterative:\n",
    "!pip install awswrangler\n",
    "import awswrangler as wr\n",
    "video_files = wr.s3.list_objects('s3://prosegur-cv-poc/dataset/prosegur-avi/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2class-endpoint-ps\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/357158.avi - fall 99.93 % - 3.8 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/357172.avi - fall 93.40 % - 3.9 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/357179.avi - fall 99.31 % - 3.7 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/357206.avi - fall 98.80 % - 4.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/357232.avi - fall 79.47 % - 4.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/357239.avi - fall 98.27 % - 0.7 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/357243.avi - fall 91.55 % - 1.1 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/357245.avi - fall 69.81 % - 1.0 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/357271.avi - fall 99.71 % - 1.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/357273.avi - fall 96.61 % - 0.7 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/357278.avi - fall 99.30 % - 1.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/357280.avi - fall 70.43 % - 1.1 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/357287.avi - fall 99.79 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/357288.avi - fall 99.57 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/357290.avi - fall 99.96 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/357291.avi - fall 99.89 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/357295.avi - fall 99.17 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/357302.avi - fall 73.38 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/357310.avi - fall 99.95 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/357985.avi - fall 98.69 % - 0.7 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/358024.avi - fall 96.19 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/358480.avi - fall 98.56 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/358498.avi - fall 99.99 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/358790.avi - fall 99.24 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/358794.avi - fall 99.99 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/358807.avi - fall 97.59 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/358908.avi - fall 73.71 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/359081.avi - fall 99.89 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/359204.avi - fall 99.25 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/359253.avi - fall 99.35 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/359260.avi - fall 97.73 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/359263.avi - fall 95.62 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/359268.avi - fall 97.91 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/359327.avi - fall 99.81 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/359334.avi - fall 99.03 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/359401.avi - fall 97.10 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/359402.avi - fall 86.88 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/359412.avi - fall 92.35 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/359414.avi - fall 99.97 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/359416.avi - fall 97.85 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/359418.avi - fall 72.74 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/359421.avi - fall 95.90 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/359424.avi - fall 99.46 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/359435.avi - fall 99.67 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/360138.avi - fall 65.83 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/365304.avi - fall 96.32 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/373831.avi - fall 94.55 % - 0.8 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/373898.avi - fall 99.93 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376809.avi - fall 99.72 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376811.avi - fall 98.77 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376828.avi - fall 92.80 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376830.avi - fall 62.54 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376832.avi - fall 99.63 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376833.avi - fall 98.83 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376835.avi - fall 96.02 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376840.avi - fall 99.24 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376842.avi - fall 98.78 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376851.avi - fall 99.90 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376873.avi - fall 99.80 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376876.avi - fall 97.33 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376878.avi - fall 99.91 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376881.avi - fall 87.67 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376882.avi - fall 89.45 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376885.avi - no_fall 85.00 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376887.avi - fall 90.71 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376890.avi - fall 67.58 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376892.avi - fall 77.86 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376905.avi - fall 99.58 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376917.avi - fall 99.82 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376919.avi - fall 99.58 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376926.avi - fall 99.71 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376929.avi - fall 99.85 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376932.avi - fall 99.91 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376943.avi - fall 99.26 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376947.avi - fall 96.66 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376972.avi - fall 99.91 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376974.avi - fall 98.98 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376975.avi - fall 99.77 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376977.avi - fall 98.50 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376984.avi - fall 99.87 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376996.avi - fall 97.57 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/376998.avi - fall 98.52 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377000.avi - fall 99.85 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377005.avi - fall 99.92 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377012.avi - fall 99.28 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377015.avi - fall 99.91 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377022.avi - fall 94.16 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377025.avi - fall 99.86 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377027.avi - fall 99.58 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377033.avi - fall 99.81 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377036.avi - fall 99.77 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377047.avi - fall 99.97 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377056.avi - no_fall 52.00 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377063.avi - fall 98.62 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377065.avi - fall 98.60 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377069.avi - fall 99.91 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377071.avi - fall 99.74 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377075.avi - fall 99.85 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377081.avi - fall 99.17 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377083.avi - fall 99.97 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377088.avi - fall 99.63 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377090.avi - fall 97.84 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377093.avi - fall 98.22 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377100.avi - fall 99.66 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377142.avi - fall 99.31 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377144.avi - fall 88.46 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377149.avi - fall 99.94 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377156.avi - fall 99.93 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377174.avi - fall 99.52 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377216.avi - fall 99.68 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377493.avi - fall 99.55 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377558.avi - fall 80.86 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377582.avi - fall 99.59 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377594.avi - fall 89.08 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377607.avi - fall 98.81 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377609.avi - fall 94.04 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377627.avi - fall 99.89 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377629.avi - fall 68.48 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377631.avi - fall 99.23 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377633.avi - fall 99.38 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377634.avi - fall 95.26 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377636.avi - fall 99.26 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377652.avi - fall 99.86 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377671.avi - fall 99.68 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377719.avi - fall 97.29 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377730.avi - fall 93.39 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377776.avi - fall 72.38 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377778.avi - fall 97.02 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377780.avi - fall 89.22 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377782.avi - fall 99.98 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377784.avi - fall 99.41 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377786.avi - fall 96.70 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377810.avi - fall 100.00 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/377816.avi - fall 97.95 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/378534.avi - fall 57.41 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/378536.avi - fall 97.33 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/379802.avi - fall 97.06 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/380486.avi - no_fall 56.66 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/380487.avi - fall 99.96 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/prosegur-avi/380492.avi - fall 70.40 % - 0.4 secs\n"
     ]
    }
   ],
   "source": [
    "print(ENDPOINT_NAME)\n",
    "\n",
    "for a in video_files:\n",
    "    data = {'S3_VIDEO_PATH': a}\n",
    "    a_time = float(time.time())\n",
    "    response = sm_runtime2.invoke_endpoint(EndpointName=ENDPOINT_NAME, ContentType='application/json',Accept='application/json',Body=json.dumps(data))\n",
    "    b_time = float(time.time())\n",
    "    #Get and print the response\n",
    "    response_body = json.loads(response['Body'].read().decode('utf-8'))\n",
    "    print('Inference on: ', data['S3_VIDEO_PATH'], '-', response_body['Predicted']['S'], \"{:.2f}\".format(float(response_body['Probability']['S'])*100), '% -', \"{:.1f}\".format(b_time - a_time), 'secs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fall properly detected on 138/141 videos (97.87%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2class-endpoint-ps\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/358844.avi - no_fall 67.29 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/360952.avi - fall 60.42 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/360986.avi - fall 98.64 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/362937.avi - fall 60.27 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/366191.avi - fall 51.75 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/367081.avi - no_fall 99.51 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/373196.avi - no_fall 97.56 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/374375.avi - fall 66.03 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/374538.avi - no_fall 98.34 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/374543.avi - no_fall 98.49 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/374590.avi - no_fall 73.86 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/374608.avi - no_fall 92.97 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/374616.avi - no_fall 57.67 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/374629.avi - no_fall 56.00 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/374983.avi - no_fall 89.07 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375017.avi - no_fall 85.63 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375026.avi - fall 83.54 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375118.avi - no_fall 66.55 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375123.avi - no_fall 98.51 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375165.avi - no_fall 97.52 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375205.avi - no_fall 63.09 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375522.avi - no_fall 96.05 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375580.avi - no_fall 98.32 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375592.avi - no_fall 98.67 % - 1.0 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375594.avi - no_fall 95.44 % - 0.7 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375609.avi - no_fall 86.92 % - 0.7 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375614.avi - no_fall 75.28 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375620.avi - no_fall 96.79 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375635.avi - fall 52.53 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375650.avi - no_fall 91.35 % - 0.7 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375663.avi - no_fall 99.59 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375669.avi - no_fall 94.49 % - 0.8 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375671.avi - no_fall 99.35 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375681.avi - no_fall 99.57 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375689.avi - fall 74.57 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375691.avi - fall 94.60 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375695.avi - no_fall 93.66 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375701.avi - fall 52.23 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375707.avi - no_fall 99.59 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375721.avi - no_fall 93.37 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375728.avi - no_fall 87.34 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375730.avi - fall 72.10 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375736.avi - no_fall 91.61 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375746.avi - no_fall 62.58 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375748.avi - no_fall 97.59 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375763.avi - no_fall 68.81 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375843.avi - fall 95.75 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375845.avi - no_fall 95.97 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375847.avi - no_fall 99.82 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375849.avi - no_fall 96.63 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375853.avi - fall 70.38 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375855.avi - fall 83.69 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375857.avi - no_fall 93.80 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375859.avi - no_fall 60.95 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375861.avi - fall 62.25 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375863.avi - fall 74.83 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375865.avi - fall 56.95 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375867.avi - no_fall 74.44 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375869.avi - no_fall 99.66 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375871.avi - no_fall 95.06 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375873.avi - no_fall 85.04 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375879.avi - no_fall 55.04 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375890.avi - fall 76.73 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375893.avi - no_fall 98.13 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375895.avi - no_fall 96.10 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375897.avi - fall 65.17 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375899.avi - no_fall 98.93 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375902.avi - no_fall 69.61 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375904.avi - fall 78.69 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375908.avi - fall 91.86 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375910.avi - no_fall 98.14 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375912.avi - no_fall 75.79 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375916.avi - no_fall 84.36 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375919.avi - no_fall 99.66 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375921.avi - no_fall 99.88 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375923.avi - no_fall 88.35 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375927.avi - no_fall 99.91 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375932.avi - no_fall 82.78 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375946.avi - no_fall 96.89 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375950.avi - no_fall 85.06 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375954.avi - no_fall 99.97 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375958.avi - no_fall 99.75 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375959.avi - no_fall 99.29 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375962.avi - no_fall 99.75 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375968.avi - fall 82.04 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375976.avi - no_fall 99.46 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375978.avi - no_fall 99.66 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375979.avi - no_fall 99.84 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375980.avi - no_fall 99.15 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375983.avi - no_fall 98.86 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375986.avi - no_fall 97.14 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375988.avi - no_fall 99.63 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/375999.avi - fall 55.37 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376020.avi - no_fall 61.94 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376073.avi - fall 71.01 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376085.avi - fall 81.17 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376089.avi - no_fall 99.84 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376097.avi - no_fall 82.21 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376101.avi - no_fall 85.10 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376107.avi - no_fall 72.58 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376109.avi - no_fall 53.97 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376124.avi - no_fall 96.61 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376126.avi - no_fall 64.11 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376131.avi - fall 90.85 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376183.avi - no_fall 97.48 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376191.avi - no_fall 86.05 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376213.avi - no_fall 99.84 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376234.avi - fall 70.63 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376247.avi - no_fall 92.26 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376258.avi - no_fall 92.18 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376262.avi - fall 65.43 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376265.avi - fall 93.19 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376271.avi - fall 81.72 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376273.avi - fall 81.44 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376281.avi - no_fall 71.25 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376287.avi - no_fall 97.80 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376291.avi - fall 85.04 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376302.avi - fall 81.90 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376346.avi - fall 72.03 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376364.avi - fall 85.38 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376367.avi - fall 98.94 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376388.avi - fall 74.93 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376405.avi - fall 93.60 % - 0.7 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376411.avi - no_fall 50.76 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376415.avi - no_fall 89.75 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376423.avi - fall 55.68 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376425.avi - no_fall 52.13 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376465.avi - no_fall 99.63 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376482.avi - no_fall 99.64 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376484.avi - fall 96.50 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376511.avi - no_fall 98.63 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376531.avi - fall 86.21 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376547.avi - fall 96.90 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376557.avi - fall 98.76 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376559.avi - no_fall 74.16 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376561.avi - fall 59.15 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376581.avi - fall 99.92 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376586.avi - no_fall 99.78 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376588.avi - no_fall 98.04 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376595.avi - fall 83.91 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376602.avi - no_fall 94.73 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376608.avi - fall 91.16 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376611.avi - fall 95.69 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376613.avi - fall 92.45 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376624.avi - fall 87.96 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376648.avi - fall 82.81 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376654.avi - fall 99.68 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376683.avi - no_fall 82.37 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376717.avi - no_fall 99.33 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376726.avi - fall 97.22 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376729.avi - fall 90.69 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376751.avi - no_fall 89.08 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376759.avi - no_fall 94.21 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376766.avi - fall 51.60 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376768.avi - no_fall 68.13 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376791.avi - fall 55.35 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376803.avi - no_fall 70.43 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376816.avi - no_fall 76.15 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376820.avi - fall 94.73 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376825.avi - fall 98.48 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376864.avi - fall 95.95 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376907.avi - fall 96.21 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376952.avi - fall 99.35 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376979.avi - fall 53.54 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376981.avi - no_fall 72.46 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/376986.avi - no_fall 68.21 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377002.avi - fall 60.39 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377006.avi - no_fall 79.95 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377010.avi - no_fall 92.66 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377017.avi - fall 97.19 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377021.avi - fall 97.74 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377030.avi - no_fall 66.84 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377054.avi - no_fall 98.77 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377094.avi - fall 98.32 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377108.avi - fall 89.46 % - 0.7 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377110.avi - fall 81.34 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377111.avi - no_fall 97.66 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377121.avi - fall 53.15 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377126.avi - no_fall 90.01 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377133.avi - no_fall 97.38 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377135.avi - no_fall 88.43 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377137.avi - no_fall 65.75 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377148.avi - fall 79.99 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377157.avi - fall 95.00 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377163.avi - no_fall 70.84 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377166.avi - fall 99.32 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377177.avi - no_fall 99.77 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377183.avi - fall 74.22 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377239.avi - fall 97.67 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377240.avi - fall 90.72 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377281.avi - fall 52.86 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377285.avi - fall 97.13 % - 0.7 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377290.avi - no_fall 68.67 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377319.avi - no_fall 99.97 % - 0.7 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377320.avi - no_fall 89.17 % - 0.7 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377327.avi - no_fall 98.95 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377331.avi - no_fall 91.04 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377341.avi - no_fall 99.87 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377353.avi - no_fall 91.05 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377357.avi - fall 57.37 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377359.avi - fall 68.47 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377361.avi - fall 90.72 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377364.avi - fall 80.92 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377371.avi - fall 56.90 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377374.avi - no_fall 74.93 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377378.avi - fall 79.58 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377404.avi - no_fall 80.45 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377408.avi - fall 96.23 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377414.avi - no_fall 91.09 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377418.avi - no_fall 95.85 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377429.avi - no_fall 95.61 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377442.avi - no_fall 73.21 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377449.avi - no_fall 88.58 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377451.avi - fall 52.09 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377456.avi - no_fall 84.88 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377467.avi - fall 98.75 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377471.avi - fall 99.00 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377495.avi - no_fall 79.77 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377505.avi - no_fall 96.48 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377510.avi - no_fall 97.77 % - 0.8 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377524.avi - fall 99.86 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377526.avi - no_fall 55.37 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377538.avi - no_fall 93.29 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377543.avi - no_fall 99.76 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377546.avi - fall 86.64 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377560.avi - fall 77.97 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377573.avi - no_fall 88.11 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377575.avi - no_fall 62.29 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377577.avi - no_fall 95.95 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377584.avi - no_fall 92.39 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377591.avi - fall 86.76 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377596.avi - no_fall 80.66 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377600.avi - no_fall 95.31 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377602.avi - fall 89.28 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377613.avi - fall 78.82 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377621.avi - no_fall 76.11 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377647.avi - no_fall 72.70 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377649.avi - no_fall 93.87 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377655.avi - fall 81.65 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377660.avi - fall 68.07 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377663.avi - no_fall 99.88 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377666.avi - no_fall 61.02 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377677.avi - fall 88.46 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377693.avi - fall 71.50 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377709.avi - fall 91.27 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377824.avi - no_fall 97.60 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377827.avi - no_fall 96.74 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377829.avi - no_fall 99.82 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377854.avi - no_fall 99.67 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377857.avi - fall 72.01 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377868.avi - no_fall 80.46 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377872.avi - no_fall 99.61 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377896.avi - fall 99.33 % - 0.7 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377914.avi - no_fall 62.80 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377917.avi - fall 65.03 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377921.avi - no_fall 76.19 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377923.avi - no_fall 98.77 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377925.avi - fall 59.68 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377930.avi - no_fall 86.14 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377932.avi - no_fall 68.29 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377934.avi - no_fall 98.97 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377940.avi - no_fall 98.08 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377943.avi - no_fall 93.42 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377952.avi - fall 92.16 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/377964.avi - fall 50.14 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378028.avi - no_fall 73.56 % - 0.7 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378049.avi - fall 90.24 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378055.avi - fall 66.93 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378057.avi - no_fall 81.45 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378060.avi - no_fall 53.30 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378071.avi - fall 99.97 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378084.avi - fall 54.30 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378093.avi - no_fall 89.27 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378112.avi - fall 86.63 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378113.avi - no_fall 61.37 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378135.avi - no_fall 70.65 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378138.avi - fall 72.29 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378145.avi - no_fall 80.08 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378150.avi - fall 65.25 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378153.avi - no_fall 73.45 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378156.avi - fall 83.70 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378167.avi - fall 77.94 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378175.avi - no_fall 91.32 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378181.avi - no_fall 77.24 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378182.avi - no_fall 79.32 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378185.avi - fall 91.22 % - 0.7 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378189.avi - no_fall 75.22 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378194.avi - no_fall 93.43 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378220.avi - no_fall 93.30 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378223.avi - no_fall 98.24 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378225.avi - no_fall 99.10 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378229.avi - fall 92.41 % - 0.7 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378251.avi - fall 98.81 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378255.avi - no_fall 76.31 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378265.avi - no_fall 98.34 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378267.avi - no_fall 95.86 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378274.avi - no_fall 99.51 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378281.avi - no_fall 93.25 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378284.avi - no_fall 99.36 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378293.avi - no_fall 98.86 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378296.avi - no_fall 78.56 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378299.avi - no_fall 96.67 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378326.avi - no_fall 99.74 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378352.avi - no_fall 87.70 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378365.avi - no_fall 83.07 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378382.avi - no_fall 93.02 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378395.avi - fall 84.30 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378406.avi - no_fall 50.94 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378416.avi - no_fall 79.78 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378442.avi - fall 98.50 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378460.avi - fall 50.74 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378472.avi - fall 99.06 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378479.avi - fall 99.29 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378514.avi - fall 75.40 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378528.avi - fall 59.73 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378531.avi - no_fall 97.85 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378544.avi - fall 96.60 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378551.avi - fall 60.06 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378586.avi - no_fall 97.71 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378632.avi - no_fall 99.29 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378643.avi - no_fall 97.49 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378650.avi - no_fall 98.66 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378671.avi - no_fall 70.47 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378680.avi - no_fall 94.40 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378682.avi - fall 76.23 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378686.avi - fall 94.73 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378698.avi - fall 95.93 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378702.avi - no_fall 96.89 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378716.avi - fall 89.70 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378729.avi - no_fall 77.65 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378744.avi - fall 78.68 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378750.avi - no_fall 94.29 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378752.avi - no_fall 95.85 % - 0.7 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378754.avi - fall 58.34 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378760.avi - no_fall 84.95 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378804.avi - no_fall 67.86 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378811.avi - no_fall 56.29 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378819.avi - no_fall 65.85 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378848.avi - fall 92.08 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378851.avi - no_fall 96.72 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378854.avi - no_fall 99.57 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378859.avi - fall 99.25 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378885.avi - fall 94.03 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378910.avi - no_fall 97.29 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378941.avi - no_fall 99.69 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378946.avi - no_fall 69.20 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378951.avi - no_fall 84.18 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378961.avi - fall 74.81 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/378992.avi - no_fall 98.20 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379005.avi - no_fall 77.69 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379014.avi - fall 56.10 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379036.avi - fall 82.47 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379050.avi - fall 65.70 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379062.avi - no_fall 93.26 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379064.avi - no_fall 94.89 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379067.avi - no_fall 76.82 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379075.avi - fall 68.73 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379078.avi - fall 57.72 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379082.avi - fall 67.74 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379088.avi - no_fall 97.25 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379091.avi - no_fall 89.25 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379093.avi - fall 95.35 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379112.avi - no_fall 67.39 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379126.avi - no_fall 93.28 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379133.avi - fall 96.64 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379138.avi - no_fall 99.54 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379140.avi - no_fall 96.03 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379142.avi - no_fall 99.08 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379144.avi - no_fall 95.84 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379146.avi - no_fall 97.02 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379154.avi - no_fall 74.70 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379158.avi - no_fall 99.36 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379161.avi - no_fall 95.18 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379167.avi - fall 81.74 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379170.avi - fall 96.41 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379173.avi - fall 94.83 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379184.avi - no_fall 51.50 % - 0.9 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379208.avi - no_fall 80.28 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379218.avi - no_fall 90.84 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379230.avi - fall 70.12 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379232.avi - no_fall 74.98 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379236.avi - fall 54.39 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379247.avi - no_fall 99.17 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379250.avi - no_fall 61.06 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379288.avi - fall 50.66 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379310.avi - no_fall 76.08 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379323.avi - no_fall 86.07 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379325.avi - fall 92.63 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379504.avi - no_fall 97.49 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379520.avi - no_fall 92.67 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379528.avi - no_fall 87.70 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379544.avi - no_fall 93.77 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379546.avi - fall 77.90 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379553.avi - fall 97.48 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379568.avi - no_fall 96.28 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379582.avi - no_fall 85.70 % - 0.7 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379587.avi - fall 94.29 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379624.avi - fall 80.64 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379639.avi - no_fall 87.79 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379653.avi - no_fall 94.44 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379664.avi - no_fall 94.15 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379691.avi - no_fall 75.38 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379711.avi - fall 51.39 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379731.avi - no_fall 64.40 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379768.avi - fall 96.99 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379769.avi - fall 99.77 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379806.avi - no_fall 78.02 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379813.avi - no_fall 61.73 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379843.avi - no_fall 99.73 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379852.avi - no_fall 57.95 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379866.avi - no_fall 76.67 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379868.avi - no_fall 96.94 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379872.avi - fall 65.46 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379875.avi - no_fall 93.89 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379878.avi - no_fall 93.87 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379880.avi - fall 79.19 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379923.avi - no_fall 88.52 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379940.avi - no_fall 65.10 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379953.avi - no_fall 98.63 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379957.avi - no_fall 62.78 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/379969.avi - no_fall 99.44 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380029.avi - no_fall 98.96 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380091.avi - fall 84.89 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380098.avi - no_fall 74.06 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380108.avi - no_fall 69.74 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380122.avi - fall 91.56 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380149.avi - fall 95.29 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380164.avi - no_fall 87.15 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380176.avi - fall 70.47 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380195.avi - no_fall 93.43 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380198.avi - no_fall 65.97 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380217.avi - no_fall 94.70 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380229.avi - no_fall 70.31 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380237.avi - no_fall 93.91 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380240.avi - no_fall 99.66 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380266.avi - no_fall 97.47 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380271.avi - no_fall 84.38 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380274.avi - fall 73.31 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380278.avi - no_fall 99.31 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380281.avi - fall 97.14 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380285.avi - no_fall 92.01 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380292.avi - no_fall 94.13 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380304.avi - fall 99.44 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380373.avi - no_fall 99.11 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380380.avi - fall 67.31 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380393.avi - no_fall 88.17 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380548.avi - no_fall 97.69 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380552.avi - no_fall 99.77 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380564.avi - fall 64.15 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380653.avi - no_fall 84.64 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380692.avi - fall 98.54 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380703.avi - no_fall 74.65 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380741.avi - no_fall 97.03 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380751.avi - no_fall 83.93 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380761.avi - fall 96.14 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380763.avi - fall 86.99 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380769.avi - fall 86.67 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380790.avi - no_fall 98.99 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380811.avi - fall 98.81 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380822.avi - fall 82.60 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380826.avi - fall 72.71 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380874.avi - no_fall 99.31 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380876.avi - no_fall 97.56 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380888.avi - fall 95.29 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/380983.avi - no_fall 99.98 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381036.avi - no_fall 81.25 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381085.avi - no_fall 99.96 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381087.avi - no_fall 89.04 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381102.avi - no_fall 58.37 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381128.avi - no_fall 99.83 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381137.avi - no_fall 95.63 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381148.avi - fall 66.66 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381150.avi - no_fall 96.46 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381152.avi - no_fall 78.82 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381169.avi - fall 78.27 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381173.avi - no_fall 98.08 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381217.avi - fall 95.39 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381222.avi - no_fall 78.90 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381225.avi - no_fall 92.99 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381271.avi - no_fall 71.63 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381305.avi - no_fall 91.79 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381501.avi - fall 57.94 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381503.avi - no_fall 72.65 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381516.avi - no_fall 96.40 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381587.avi - no_fall 72.79 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381590.avi - no_fall 75.72 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381597.avi - no_fall 99.80 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381628.avi - no_fall 92.00 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381633.avi - no_fall 99.09 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381639.avi - no_fall 63.52 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381649.avi - no_fall 98.85 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381652.avi - no_fall 98.51 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381665.avi - fall 96.56 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381718.avi - fall 87.13 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381723.avi - fall 55.58 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381729.avi - no_fall 77.73 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381763.avi - no_fall 97.56 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381766.avi - fall 98.62 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381768.avi - fall 81.81 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381771.avi - fall 95.53 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381780.avi - fall 79.64 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381795.avi - fall 95.84 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381850.avi - no_fall 53.07 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381860.avi - no_fall 98.96 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381871.avi - no_fall 99.06 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381885.avi - fall 99.96 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381922.avi - no_fall 72.41 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381939.avi - no_fall 67.42 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381959.avi - fall 87.80 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/381991.avi - fall 86.02 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/382035.avi - fall 94.32 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/382043.avi - no_fall 73.36 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/383356.avi - no_fall 71.99 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/383570.avi - fall 99.91 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/383579.avi - no_fall 79.46 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/383705.avi - fall 66.36 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/383799.avi - no_fall 92.06 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/383895.avi - fall 97.51 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/383968.avi - fall 91.83 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/383993.avi - fall 98.62 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384271.avi - no_fall 99.23 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384274.avi - fall 77.14 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384291.avi - no_fall 99.78 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384339.avi - no_fall 68.36 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384346.avi - fall 98.15 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384350.avi - no_fall 97.34 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384402.avi - no_fall 90.30 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384469.avi - no_fall 98.55 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384472.avi - no_fall 56.96 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384475.avi - fall 63.93 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384477.avi - no_fall 91.07 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384492.avi - fall 92.24 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384543.avi - no_fall 71.86 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384547.avi - fall 98.44 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384563.avi - no_fall 78.03 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384567.avi - fall 68.59 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384596.avi - fall 92.13 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384601.avi - no_fall 67.87 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384658.avi - no_fall 94.21 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384705.avi - no_fall 97.27 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384715.avi - fall 70.37 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384720.avi - fall 78.43 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384726.avi - no_fall 72.53 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384728.avi - no_fall 72.53 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384772.avi - fall 62.97 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384791.avi - no_fall 95.78 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384806.avi - no_fall 77.90 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384827.avi - no_fall 98.39 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384833.avi - no_fall 97.23 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384835.avi - no_fall 63.25 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384843.avi - no_fall 98.43 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384845.avi - no_fall 98.53 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384871.avi - fall 94.10 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384875.avi - fall 92.92 % - 0.3 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384897.avi - no_fall 93.49 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384906.avi - no_fall 89.23 % - 0.6 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384910.avi - no_fall 97.67 % - 0.4 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384941.avi - fall 80.47 % - 0.5 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/384985.avi - no_fall 99.50 % - 0.2 secs\n",
      "Inference on:  s3://prosegur-cv-poc/dataset/negative-avi/385000.avi - no_fall 99.19 % - 0.2 secs\n"
     ]
    }
   ],
   "source": [
    "###Negative cases:\n",
    "video_files = wr.s3.list_objects('s3://prosegur-cv-poc/dataset/negative-avi/')\n",
    "\n",
    "print(ENDPOINT_NAME)\n",
    "\n",
    "for a in video_files:\n",
    "    data = {'S3_VIDEO_PATH': a}\n",
    "    a_time = float(time.time())\n",
    "    response = sm_runtime2.invoke_endpoint(EndpointName=ENDPOINT_NAME, ContentType='application/json',Accept='application/json',Body=json.dumps(data))\n",
    "    b_time = float(time.time())\n",
    "    #Get and print the response\n",
    "    response_body = json.loads(response['Body'].read().decode('utf-8'))\n",
    "    print('Inference on: ', data['S3_VIDEO_PATH'], '-', response_body['Predicted']['S'], \"{:.2f}\".format(float(response_body['Probability']['S'])*100), '% -', \"{:.1f}\".format(b_time - a_time), 'secs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No-fall properly detected on 350/560 videos (62.50%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Symbol dense0_fwd>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol = mx.sym.load('./model-symbol.json')\n",
    "symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
